/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/RecurrentSNN/Uniform/512units/dataset/shddataset/
made weight variables and loss histogram
Epoch 1: loss=19.47501
Epoch 2: loss=3.50456
Epoch 3: loss=2.92286
Epoch 4: loss=2.63609
Epoch 5: loss=2.48666
Epoch 6: loss=2.28103
Epoch 7: loss=2.21065
Epoch 8: loss=2.03716
Epoch 9: loss=1.94356
Epoch 10: loss=1.83323
Trained for 10 epochs
Training accuracy: 0.571
Epoch 1: loss=1.74593
Epoch 2: loss=1.68496
Epoch 3: loss=1.62945
Epoch 4: loss=1.54286
Epoch 5: loss=1.46036
Epoch 6: loss=1.43585
Epoch 7: loss=1.36995
Epoch 8: loss=1.29331
Epoch 9: loss=1.28431
Epoch 10: loss=1.26109
Epoch 11: loss=1.17139
Epoch 12: loss=1.14613
Epoch 13: loss=1.10230
Epoch 14: loss=1.06276
Epoch 15: loss=1.04403
Epoch 16: loss=1.04166
Epoch 17: loss=1.00436
Epoch 18: loss=0.98805
Epoch 19: loss=0.94935
Epoch 20: loss=0.93875
Epoch 21: loss=0.90014
Epoch 22: loss=0.90369
Epoch 23: loss=0.86008
Epoch 24: loss=0.87222
Epoch 25: loss=0.86247
Epoch 26: loss=0.82620
Epoch 27: loss=0.83229
Epoch 28: loss=0.77996
Epoch 29: loss=0.77302
Epoch 30: loss=0.76690
Epoch 31: loss=0.76157
Epoch 32: loss=0.72044
Epoch 33: loss=0.71134
Epoch 34: loss=0.72279
Epoch 35: loss=0.70809
Epoch 36: loss=0.69759
Epoch 37: loss=0.67181
Epoch 38: loss=0.65797
Epoch 39: loss=0.64802
Epoch 40: loss=0.64815
Epoch 41: loss=0.62599
Epoch 42: loss=0.63752
Epoch 43: loss=0.63448
Epoch 44: loss=0.61496
Epoch 45: loss=0.60770
Epoch 46: loss=0.59498
Epoch 47: loss=0.59517
Epoch 48: loss=0.62429
Epoch 49: loss=0.58909
Epoch 50: loss=0.57341
Epoch 51: loss=0.57888
Epoch 52: loss=0.57340
Epoch 53: loss=0.55092
Epoch 54: loss=0.53035
Epoch 55: loss=0.53780
Epoch 56: loss=0.56128
Epoch 57: loss=0.52942
Epoch 58: loss=0.50983
Epoch 59: loss=0.51494
Epoch 60: loss=0.53700
Epoch 61: loss=0.51892
Epoch 62: loss=0.49428
Epoch 63: loss=0.47189
Epoch 64: loss=0.48933
Epoch 65: loss=0.48337
Epoch 66: loss=0.46907
Epoch 67: loss=0.49727
Epoch 68: loss=0.47611
Epoch 69: loss=0.44428
Epoch 70: loss=0.44780
Epoch 71: loss=0.45494
Epoch 72: loss=0.44578
Epoch 73: loss=0.45741
Epoch 74: loss=0.42823
Epoch 75: loss=0.44147
Epoch 76: loss=0.44151
Epoch 77: loss=0.43821
Epoch 78: loss=0.42726
Epoch 79: loss=0.41867
Epoch 80: loss=0.42025
Epoch 81: loss=0.41923
Epoch 82: loss=0.40986
Epoch 83: loss=0.43645
Epoch 84: loss=0.45652
Epoch 85: loss=0.45291
Epoch 86: loss=0.43594
Epoch 87: loss=0.42666
Epoch 88: loss=0.41991
Epoch 89: loss=0.41174
Epoch 90: loss=0.41779
Epoch 91: loss=0.42015
Epoch 92: loss=0.42683
Epoch 93: loss=0.41210
Epoch 94: loss=0.39989
Epoch 95: loss=0.39059
Epoch 96: loss=0.40705
Epoch 97: loss=0.38996
Epoch 98: loss=0.40439
Epoch 99: loss=0.38648
Epoch 100: loss=0.42006
Epoch 101: loss=0.38886
Epoch 102: loss=0.40040
Epoch 103: loss=0.39318
Epoch 104: loss=0.38124
Epoch 105: loss=0.37474
Epoch 106: loss=0.38418
Epoch 107: loss=0.39519
Epoch 108: loss=0.37272
Epoch 109: loss=0.35184
Epoch 110: loss=0.37112
Epoch 111: loss=0.35663
Epoch 112: loss=0.35427
Epoch 113: loss=0.37064
Epoch 114: loss=0.34499
Epoch 115: loss=0.35762
Epoch 116: loss=0.36323
Epoch 117: loss=0.37222
Epoch 118: loss=0.34530
Epoch 119: loss=0.33254
Epoch 120: loss=0.34852
Epoch 121: loss=0.34872
Epoch 122: loss=0.31847
Epoch 123: loss=0.32168
Epoch 124: loss=0.32478
Epoch 125: loss=0.31868
Epoch 126: loss=0.31279
Epoch 127: loss=0.31374
Epoch 128: loss=0.29763
Epoch 129: loss=0.31099
Epoch 130: loss=0.30833
Epoch 131: loss=0.31491
Epoch 132: loss=0.30675
Epoch 133: loss=0.29364
Epoch 134: loss=0.29865
Epoch 135: loss=0.30166
Epoch 136: loss=0.29516
Epoch 137: loss=0.29853
Epoch 138: loss=0.31524
Epoch 139: loss=0.30238
Epoch 140: loss=0.29161
Epoch 141: loss=0.29051
Epoch 142: loss=0.29001
Epoch 143: loss=0.28944
Epoch 144: loss=0.27086
Epoch 145: loss=0.28211
Epoch 146: loss=0.28387
Epoch 147: loss=0.28862
Epoch 148: loss=0.26824
Epoch 149: loss=0.29748
Epoch 150: loss=0.27845
Epoch 151: loss=0.27583
Epoch 152: loss=0.30516
Epoch 153: loss=0.26699
Epoch 154: loss=0.27394
Epoch 155: loss=0.26723
Epoch 156: loss=0.26584
Epoch 157: loss=0.25831
Epoch 158: loss=0.26341
Epoch 159: loss=0.25604
Epoch 160: loss=0.26352
Epoch 161: loss=0.25739
Epoch 162: loss=0.25341
Epoch 163: loss=0.24998
Epoch 164: loss=0.25082
Epoch 165: loss=0.25330
Epoch 166: loss=0.24510
Epoch 167: loss=0.23228
Epoch 168: loss=0.24186
Epoch 169: loss=0.26872
Epoch 170: loss=0.23394
Epoch 171: loss=0.23290
Epoch 172: loss=0.23561
Epoch 173: loss=0.25289
Epoch 174: loss=0.24924
Epoch 175: loss=0.25602
Epoch 176: loss=0.24885
Epoch 177: loss=0.25017
Epoch 178: loss=0.24300
Epoch 179: loss=0.24024
Epoch 180: loss=0.23342
Epoch 181: loss=0.23611
Epoch 182: loss=0.24986
Epoch 183: loss=0.23370
Epoch 184: loss=0.24754
Epoch 185: loss=0.25139
Epoch 186: loss=0.24182
Epoch 187: loss=0.24005
Epoch 188: loss=0.22925
Epoch 189: loss=0.25267
Epoch 190: loss=0.24806
Epoch 191: loss=0.23901
Epoch 192: loss=0.23541
Epoch 193: loss=0.22618
Epoch 194: loss=0.24171
Epoch 195: loss=0.24547
Epoch 196: loss=0.23475
Epoch 197: loss=0.22393
Epoch 198: loss=0.22808
Epoch 199: loss=0.23657
Epoch 200: loss=0.23282
Training accuracy: 0.965
Test accuracy: 0.594

File list dumped

Saved in file
