/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/256units/dataset/shddataset/
2 layered 256 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
Epoch 1: loss=15.33994
Epoch 2: loss=6.88222
Epoch 3: loss=4.43757
Epoch 4: loss=3.52935
Epoch 5: loss=3.19857
Epoch 6: loss=3.01495
Epoch 7: loss=2.94879
Epoch 8: loss=2.89896
Epoch 9: loss=2.83829
Epoch 10: loss=2.79676
Trained for 10 epochs
Training accuracy: 0.192
Epoch 1: loss=2.76874
Epoch 2: loss=2.72584
Epoch 3: loss=2.71471
Epoch 4: loss=2.70683
Epoch 5: loss=2.70946
Epoch 6: loss=2.70028
Epoch 7: loss=2.67020
Epoch 8: loss=2.66226
Epoch 9: loss=2.63039
Epoch 10: loss=2.60322
Epoch 11: loss=2.55664
Epoch 12: loss=2.52513
Epoch 13: loss=2.49479
Epoch 14: loss=2.46733
Epoch 15: loss=2.46382
Epoch 16: loss=2.45902
Epoch 17: loss=2.42849
Epoch 18: loss=2.38960
Epoch 19: loss=2.35014
Epoch 20: loss=2.30007
Epoch 21: loss=2.27147
Epoch 22: loss=2.25903
Epoch 23: loss=2.24465
Epoch 24: loss=2.22429
Epoch 25: loss=2.24221
Epoch 26: loss=2.24227
Epoch 27: loss=2.23291
Epoch 28: loss=2.18342
Epoch 29: loss=2.17450
Epoch 30: loss=2.14272
Epoch 31: loss=2.12254
Epoch 32: loss=2.06780
Epoch 33: loss=2.03795
Epoch 34: loss=2.06028
Epoch 35: loss=2.04859
Epoch 36: loss=2.04379
Epoch 37: loss=2.04642
Epoch 38: loss=2.02696
Epoch 39: loss=1.97918
Epoch 40: loss=1.97502
Epoch 41: loss=1.93915
Epoch 42: loss=1.92317
Epoch 43: loss=1.89031
Epoch 44: loss=1.86566
Epoch 45: loss=1.86368
Epoch 46: loss=1.85417
Epoch 47: loss=1.85172
Epoch 48: loss=1.82109
Epoch 49: loss=1.79877
Epoch 50: loss=1.77688
Epoch 51: loss=1.76808
Epoch 52: loss=1.75038
Epoch 53: loss=1.73434
Epoch 54: loss=1.72256
Epoch 55: loss=1.72309
Epoch 56: loss=1.70775
Epoch 57: loss=1.70074
Epoch 58: loss=1.67977
Epoch 59: loss=1.68903
Epoch 60: loss=1.68411
Epoch 61: loss=1.65640
Epoch 62: loss=1.64127
Epoch 63: loss=1.63511
Epoch 64: loss=1.64019
Epoch 65: loss=1.61535
Epoch 66: loss=1.60641
Epoch 67: loss=1.57856
Epoch 68: loss=1.56361
Epoch 69: loss=1.57988
Epoch 70: loss=1.56115
Epoch 71: loss=1.56679
Epoch 72: loss=1.54729
Epoch 73: loss=1.51657
Epoch 74: loss=1.51021
Epoch 75: loss=1.47033
Epoch 76: loss=1.47041
Epoch 77: loss=1.46628
Epoch 78: loss=1.44999
Epoch 79: loss=1.44784
Epoch 80: loss=1.44848
Epoch 81: loss=1.43747
Epoch 82: loss=1.42739
Epoch 83: loss=1.43061
Epoch 84: loss=1.41870
Epoch 85: loss=1.39459
Epoch 86: loss=1.41481
Epoch 87: loss=1.40871
Epoch 88: loss=1.41382
Epoch 89: loss=1.39789
Epoch 90: loss=1.38171
Epoch 91: loss=1.37283
Epoch 92: loss=1.34767
Epoch 93: loss=1.35163
Epoch 94: loss=1.34330
Epoch 95: loss=1.33170
Epoch 96: loss=1.32430
Epoch 97: loss=1.32079
Epoch 98: loss=1.29358
Epoch 99: loss=1.29407
Epoch 100: loss=1.27485
Epoch 101: loss=1.26784
Epoch 102: loss=1.27665
Epoch 103: loss=1.27038
Epoch 104: loss=1.24655
Epoch 105: loss=1.24700
Epoch 106: loss=1.24195
Epoch 107: loss=1.24138
Epoch 108: loss=1.23144
Epoch 109: loss=1.22299
Epoch 110: loss=1.21610
Epoch 111: loss=1.21642
Epoch 112: loss=1.20012
Epoch 113: loss=1.21750
Epoch 114: loss=1.20839
Epoch 115: loss=1.21438
Epoch 116: loss=1.19686
Epoch 117: loss=1.18451
Epoch 118: loss=1.18105
Epoch 119: loss=1.18384
Epoch 120: loss=1.18027
Epoch 121: loss=1.17410
Epoch 122: loss=1.18626
Epoch 123: loss=1.17807
Epoch 124: loss=1.17051
Epoch 125: loss=1.15419
Epoch 126: loss=1.16341
Epoch 127: loss=1.15072
Epoch 128: loss=1.14948
Epoch 129: loss=1.13096
Epoch 130: loss=1.13725
Epoch 131: loss=1.12610
Epoch 132: loss=1.12463
Epoch 133: loss=1.13177
Epoch 134: loss=1.10906
Epoch 135: loss=1.10812
Epoch 136: loss=1.10540
Epoch 137: loss=1.10630
Epoch 138: loss=1.09367
Epoch 139: loss=1.09335
Epoch 140: loss=1.09467
Epoch 141: loss=1.07901
Epoch 142: loss=1.07418
Epoch 143: loss=1.05528
Epoch 144: loss=1.06714
Epoch 145: loss=1.07184
Epoch 146: loss=1.05055
Epoch 147: loss=1.04529
Epoch 148: loss=1.04592
Epoch 149: loss=1.04066
Epoch 150: loss=1.03121
Epoch 151: loss=1.03039
Epoch 152: loss=1.02497
Epoch 153: loss=1.03594
Epoch 154: loss=1.01819
Epoch 155: loss=1.02406
Epoch 156: loss=1.02827
Epoch 157: loss=1.03409
Epoch 158: loss=1.01954
Epoch 159: loss=0.99922
Epoch 160: loss=0.98708
Epoch 161: loss=1.00356
Epoch 162: loss=0.98641
Epoch 163: loss=0.98239
Epoch 164: loss=0.99952
Epoch 165: loss=0.98703
Epoch 166: loss=0.98263
Epoch 167: loss=0.96697
Epoch 168: loss=0.97361
Epoch 169: loss=0.97198
Epoch 170: loss=0.98130
Epoch 171: loss=0.96062
Epoch 172: loss=0.96737
Epoch 173: loss=0.96784
Epoch 174: loss=0.96218
Epoch 175: loss=0.95580
Epoch 176: loss=0.93945
Epoch 177: loss=0.92979
Epoch 178: loss=0.92665
Epoch 179: loss=0.93537
Epoch 180: loss=0.95716
Epoch 181: loss=0.94278
Epoch 182: loss=0.94547
Epoch 183: loss=0.95321
Epoch 184: loss=0.96523
Epoch 185: loss=0.96983
Epoch 186: loss=0.98189
Epoch 187: loss=0.97996
Epoch 188: loss=0.99152
Epoch 189: loss=0.96256
Epoch 190: loss=0.95859
Epoch 191: loss=0.97840
Epoch 192: loss=0.98119
Epoch 193: loss=0.98624
Epoch 194: loss=0.98562
Epoch 195: loss=0.96312
Epoch 196: loss=0.96236
Epoch 197: loss=0.95108
Epoch 198: loss=0.95213
Epoch 199: loss=0.92735
Epoch 200: loss=0.93026
Training accuracy: 0.770
Test accuracy: 0.606

File list dumped

Saved in file
