/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/256units/dataset/shddataset/
2 layered 256 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
The file is present.
Epoch 1: loss=0.64787
Epoch 2: loss=0.64052
Epoch 3: loss=0.65262
Epoch 4: loss=0.65577
Epoch 5: loss=0.66088
Epoch 6: loss=0.66593
Epoch 7: loss=0.65074
Epoch 8: loss=0.63699
Epoch 9: loss=0.66553
Epoch 10: loss=0.68160
Trained for 10 epochs
Training accuracy: 0.842
Epoch 1: loss=0.66619
Epoch 2: loss=0.69223
Epoch 3: loss=0.67648
Epoch 4: loss=0.64981
Epoch 5: loss=0.63570
Epoch 6: loss=0.65891
Epoch 7: loss=0.65945
Epoch 8: loss=0.65269
Epoch 9: loss=0.65596
Epoch 10: loss=0.65664
Epoch 11: loss=0.64913
Epoch 12: loss=0.64637
Epoch 13: loss=0.64844
Epoch 14: loss=0.65312
Epoch 15: loss=0.68296
Epoch 16: loss=0.66635
Epoch 17: loss=0.68058
Epoch 18: loss=0.65673
Epoch 19: loss=0.65522
Epoch 20: loss=0.64323
Epoch 21: loss=0.64282
Epoch 22: loss=0.65444
Epoch 23: loss=0.65238
Epoch 24: loss=0.64043
Epoch 25: loss=0.64529
Epoch 26: loss=0.65367
Epoch 27: loss=0.66402
Epoch 28: loss=0.64961
Epoch 29: loss=0.64721
Epoch 30: loss=0.65300
Epoch 31: loss=0.64000
Epoch 32: loss=0.61753
Epoch 33: loss=0.63607
Epoch 34: loss=0.62980
Epoch 35: loss=0.65399
Epoch 36: loss=0.66948
Epoch 37: loss=0.66031
Epoch 38: loss=0.67405
Epoch 39: loss=0.66921
Epoch 40: loss=0.69837
Epoch 41: loss=0.67170
Epoch 42: loss=0.66729
Epoch 43: loss=0.71034
Epoch 44: loss=0.70498
Epoch 45: loss=0.69655
Epoch 46: loss=0.70301
Epoch 47: loss=0.69955
Epoch 48: loss=0.69794
Epoch 49: loss=0.67506
Epoch 50: loss=0.66826
Epoch 51: loss=0.67868
Epoch 52: loss=0.66058
Epoch 53: loss=0.64559
Epoch 54: loss=0.65852
Epoch 55: loss=0.63855
Epoch 56: loss=0.63986
Epoch 57: loss=0.68084
Epoch 58: loss=0.67521
Epoch 59: loss=0.66878
Epoch 60: loss=0.66070
Epoch 61: loss=0.65815
Epoch 62: loss=0.66341
Epoch 63: loss=0.64651
Epoch 64: loss=0.65558
Epoch 65: loss=0.67152
Epoch 66: loss=0.65969
Epoch 67: loss=0.63638
Epoch 68: loss=0.64075
Epoch 69: loss=0.64622
Epoch 70: loss=0.66317
Epoch 71: loss=0.63223
Epoch 72: loss=0.63420
Epoch 73: loss=0.61085
Epoch 74: loss=0.63226
Epoch 75: loss=0.63171
Epoch 76: loss=0.62410
Epoch 77: loss=0.64192
Epoch 78: loss=0.63006
Epoch 79: loss=0.62906
Epoch 80: loss=0.62358
Epoch 81: loss=0.61614
Epoch 82: loss=0.61383
Epoch 83: loss=0.61153
Epoch 84: loss=0.62368
Epoch 85: loss=0.64369
Epoch 86: loss=0.63189
Epoch 87: loss=0.61757
Epoch 88: loss=0.61505
Epoch 89: loss=0.64224
Epoch 90: loss=0.64121
Epoch 91: loss=0.62070
Epoch 92: loss=0.62046
Epoch 93: loss=0.61499
Epoch 94: loss=0.59237
Epoch 95: loss=0.59501
Epoch 96: loss=0.59535
Epoch 97: loss=0.59674
Epoch 98: loss=0.60916
Epoch 99: loss=0.58163
Epoch 100: loss=0.59332
Epoch 101: loss=0.60394
Epoch 102: loss=0.61226
Epoch 103: loss=0.60153
Epoch 104: loss=0.61830
Epoch 105: loss=0.61463
Epoch 106: loss=0.60724
Epoch 107: loss=0.60364
Epoch 108: loss=0.60821
Epoch 109: loss=0.58628
Epoch 110: loss=0.58939
Epoch 111: loss=0.57263
Epoch 112: loss=0.60318
Epoch 113: loss=0.58310
Epoch 114: loss=0.61014
Epoch 115: loss=0.59142
Epoch 116: loss=0.60376
Epoch 117: loss=0.59182
Epoch 118: loss=0.61930
Epoch 119: loss=0.62456
Epoch 120: loss=0.61170
Epoch 121: loss=0.61933
Epoch 122: loss=0.62049
Epoch 123: loss=0.63440
Epoch 124: loss=0.61966
Epoch 125: loss=0.63010
Epoch 126: loss=0.59031
Epoch 127: loss=0.60204
Epoch 128: loss=0.59604
Epoch 129: loss=0.59652
Epoch 130: loss=0.60394
Epoch 131: loss=0.58412
Epoch 132: loss=0.58191
Epoch 133: loss=0.58309
Epoch 134: loss=0.58680
Epoch 135: loss=0.59547
Epoch 136: loss=0.59166
Epoch 137: loss=0.58937
Epoch 138: loss=0.59511
Epoch 139: loss=0.58065
Epoch 140: loss=0.57071
Epoch 141: loss=0.56902
Epoch 142: loss=0.56824
Epoch 143: loss=0.57400
Epoch 144: loss=0.57579
Epoch 145: loss=0.57706
Epoch 146: loss=0.57759
Epoch 147: loss=0.57902
Epoch 148: loss=0.57645
Epoch 149: loss=0.56531
Epoch 150: loss=0.59952
Epoch 151: loss=0.62660
Epoch 152: loss=0.60349
Epoch 153: loss=0.59986
Epoch 154: loss=0.58241
Epoch 155: loss=0.58454
Epoch 156: loss=0.58170
Epoch 157: loss=0.57047
Epoch 158: loss=0.57772
Epoch 159: loss=0.57152
Epoch 160: loss=0.58087
Epoch 161: loss=0.59904
Epoch 162: loss=0.60025
Epoch 163: loss=0.59602
Epoch 164: loss=0.57598
Epoch 165: loss=0.58081
Epoch 166: loss=0.61008
Epoch 167: loss=0.63088
Epoch 168: loss=0.62211
Epoch 169: loss=0.58912
Epoch 170: loss=0.58429
Epoch 171: loss=0.58610
Epoch 172: loss=0.57255
Epoch 173: loss=0.58595
Epoch 174: loss=0.60171
Epoch 175: loss=0.61490
Epoch 176: loss=0.62901
Epoch 177: loss=0.61326
Epoch 178: loss=0.59379
Epoch 179: loss=0.60366
Epoch 180: loss=0.58828
Epoch 181: loss=0.56881
Epoch 182: loss=0.60350
Epoch 183: loss=0.59782
Epoch 184: loss=0.59020
Epoch 185: loss=0.56522
Epoch 186: loss=0.58223
Epoch 187: loss=0.57870
Epoch 188: loss=0.56316
Epoch 189: loss=0.55073
Epoch 190: loss=0.54551
Epoch 191: loss=0.57816
Epoch 192: loss=0.58210
Epoch 193: loss=0.56239
Epoch 194: loss=0.54805
Epoch 195: loss=0.58168
Epoch 196: loss=0.59269
Epoch 197: loss=0.58403
Epoch 198: loss=0.62712
Epoch 199: loss=0.63780
Epoch 200: loss=0.63485
Training accuracy: 0.865
Test accuracy: 0.592

File list dumped

Saved in file
