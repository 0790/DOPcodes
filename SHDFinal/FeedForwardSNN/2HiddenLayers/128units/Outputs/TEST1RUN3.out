/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/128units/dataset/shddataset/
2 layered 128 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
The file is present.
Epoch 1: loss=1.10511
Epoch 2: loss=1.09559
Epoch 3: loss=1.09688
Epoch 4: loss=1.08996
Epoch 5: loss=1.10310
Epoch 6: loss=1.11034
Epoch 7: loss=1.10090
Epoch 8: loss=1.08039
Epoch 9: loss=1.08318
Epoch 10: loss=1.08613
Trained for 10 epochs
Training accuracy: 0.694
Epoch 1: loss=1.08699
Epoch 2: loss=1.09519
Epoch 3: loss=1.09265
Epoch 4: loss=1.10170
Epoch 5: loss=1.10115
Epoch 6: loss=1.08410
Epoch 7: loss=1.07545
Epoch 8: loss=1.08025
Epoch 9: loss=1.10375
Epoch 10: loss=1.08003
Epoch 11: loss=1.08576
Epoch 12: loss=1.08768
Epoch 13: loss=1.08684
Epoch 14: loss=1.07704
Epoch 15: loss=1.06908
Epoch 16: loss=1.07968
Epoch 17: loss=1.07885
Epoch 18: loss=1.07270
Epoch 19: loss=1.07277
Epoch 20: loss=1.08138
Epoch 21: loss=1.08237
Epoch 22: loss=1.09551
Epoch 23: loss=1.07995
Epoch 24: loss=1.06539
Epoch 25: loss=1.05787
Epoch 26: loss=1.06617
Epoch 27: loss=1.07393
Epoch 28: loss=1.08549
Epoch 29: loss=1.08152
Epoch 30: loss=1.07483
Epoch 31: loss=1.07166
Epoch 32: loss=1.06668
Epoch 33: loss=1.05874
Epoch 34: loss=1.05556
Epoch 35: loss=1.05025
Epoch 36: loss=1.04914
Epoch 37: loss=1.06291
Epoch 38: loss=1.07194
Epoch 39: loss=1.05734
Epoch 40: loss=1.06130
Epoch 41: loss=1.06772
Epoch 42: loss=1.04809
Epoch 43: loss=1.03553
Epoch 44: loss=1.05326
Epoch 45: loss=1.04381
Epoch 46: loss=1.03484
Epoch 47: loss=1.03779
Epoch 48: loss=1.03671
Epoch 49: loss=1.02595
Epoch 50: loss=1.05088
Epoch 51: loss=1.03465
Epoch 52: loss=1.03390
Epoch 53: loss=1.02992
Epoch 54: loss=1.03429
Epoch 55: loss=1.03639
Epoch 56: loss=1.03178
Epoch 57: loss=1.03297
Epoch 58: loss=1.03094
Epoch 59: loss=1.03007
Epoch 60: loss=1.02828
Epoch 61: loss=1.03454
Epoch 62: loss=1.03227
Epoch 63: loss=1.03527
Epoch 64: loss=1.06236
Epoch 65: loss=1.06472
Epoch 66: loss=1.06442
Epoch 67: loss=1.08323
Epoch 68: loss=1.06686
Epoch 69: loss=1.04272
Epoch 70: loss=1.04332
Epoch 71: loss=1.04359
Epoch 72: loss=1.04437
Epoch 73: loss=1.04082
Epoch 74: loss=1.07798
Epoch 75: loss=1.05008
Epoch 76: loss=1.06191
Epoch 77: loss=1.04552
Epoch 78: loss=1.04468
Epoch 79: loss=1.03682
Epoch 80: loss=1.03335
Epoch 81: loss=1.04689
Epoch 82: loss=1.07440
Epoch 83: loss=1.10021
Epoch 84: loss=1.08737
Epoch 85: loss=1.08868
Epoch 86: loss=1.08649
Epoch 87: loss=1.05876
Epoch 88: loss=1.05706
Epoch 89: loss=1.05582
Epoch 90: loss=1.10087
Epoch 91: loss=1.13360
Epoch 92: loss=1.17765
Epoch 93: loss=1.13738
Epoch 94: loss=1.14402
Epoch 95: loss=1.14440
Epoch 96: loss=1.16714
Epoch 97: loss=1.14893
Epoch 98: loss=1.14917
Epoch 99: loss=1.14110
Epoch 100: loss=1.11856
Epoch 101: loss=1.07503
Epoch 102: loss=1.07215
Epoch 103: loss=1.05392
Epoch 104: loss=1.03992
Epoch 105: loss=1.04381
Epoch 106: loss=1.04584
Epoch 107: loss=1.04762
Epoch 108: loss=1.03018
Epoch 109: loss=1.00974
Epoch 110: loss=1.00519
Epoch 111: loss=1.01846
Epoch 112: loss=1.00544
Epoch 113: loss=1.00352
Epoch 114: loss=1.01209
Epoch 115: loss=1.00786
Epoch 116: loss=0.99143
Epoch 117: loss=0.98757
Epoch 118: loss=1.00293
Epoch 119: loss=0.99406
Epoch 120: loss=0.99832
Epoch 121: loss=1.00627
Epoch 122: loss=0.99543
Epoch 123: loss=0.99830
Epoch 124: loss=1.03155
Epoch 125: loss=1.02830
Epoch 126: loss=1.03016
Epoch 127: loss=1.03076
Epoch 128: loss=1.02299
Epoch 129: loss=1.00930
Epoch 130: loss=1.02234
Epoch 131: loss=1.00841
Epoch 132: loss=1.02448
Epoch 133: loss=1.01870
Epoch 134: loss=1.00458
Epoch 135: loss=1.00866
Epoch 136: loss=1.00560
Epoch 137: loss=0.99657
Epoch 138: loss=0.98331
Epoch 139: loss=0.99624
Epoch 140: loss=1.00170
Epoch 141: loss=0.99796
Epoch 142: loss=0.99880
Epoch 143: loss=0.99223
Epoch 144: loss=0.99075
Epoch 145: loss=1.00513
Epoch 146: loss=1.01060
Epoch 147: loss=1.01048
Epoch 148: loss=1.00030
Epoch 149: loss=1.00737
Epoch 150: loss=0.98586
Epoch 151: loss=1.00794
Epoch 152: loss=0.99408
Epoch 153: loss=0.99015
Epoch 154: loss=0.99549
Epoch 155: loss=1.00935
Epoch 156: loss=1.00995
Epoch 157: loss=0.97638
Epoch 158: loss=0.99143
Epoch 159: loss=0.98633
Epoch 160: loss=0.97053
Epoch 161: loss=0.98688
Epoch 162: loss=0.98531
Epoch 163: loss=0.99221
Epoch 164: loss=0.98415
Epoch 165: loss=0.97444
Epoch 166: loss=0.98627
Epoch 167: loss=0.97949
Epoch 168: loss=0.97961
Epoch 169: loss=0.99854
Epoch 170: loss=0.99386
Epoch 171: loss=1.00024
Epoch 172: loss=0.98677
Epoch 173: loss=0.96350
Epoch 174: loss=0.97510
Epoch 175: loss=0.97261
Epoch 176: loss=0.98070
Epoch 177: loss=0.96716
Epoch 178: loss=0.97159
Epoch 179: loss=0.96500
Epoch 180: loss=0.97525
Epoch 181: loss=0.98829
Epoch 182: loss=0.96614
Epoch 183: loss=0.98163
Epoch 184: loss=0.97606
Epoch 185: loss=0.96220
Epoch 186: loss=0.99325
Epoch 187: loss=1.00876
Epoch 188: loss=1.00174
Epoch 189: loss=0.98823
Epoch 190: loss=1.00860
Epoch 191: loss=1.00711
Epoch 192: loss=1.00684
Epoch 193: loss=0.99182
Epoch 194: loss=0.99775
Epoch 195: loss=0.97976
Epoch 196: loss=1.00737
Epoch 197: loss=1.02241
Epoch 198: loss=1.00313
Epoch 199: loss=0.98915
Epoch 200: loss=0.98717
Training accuracy: 0.741
Test accuracy: 0.540

File list dumped

Saved in file
