/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/128units/dataset/shddataset/
2 layered 128 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
The file is present.
Epoch 1: loss=0.93525
Epoch 2: loss=0.93262
Epoch 3: loss=0.94128
Epoch 4: loss=0.94092
Epoch 5: loss=0.92970
Epoch 6: loss=0.92990
Epoch 7: loss=0.92993
Epoch 8: loss=0.93911
Epoch 9: loss=0.92737
Epoch 10: loss=0.92079
Trained for 10 epochs
Training accuracy: 0.762
Epoch 1: loss=0.92866
Epoch 2: loss=0.92776
Epoch 3: loss=0.92736
Epoch 4: loss=0.91685
Epoch 5: loss=0.91703
Epoch 6: loss=0.93577
Epoch 7: loss=0.91293
Epoch 8: loss=0.91505
Epoch 9: loss=0.93901
Epoch 10: loss=0.95956
Epoch 11: loss=0.92024
Epoch 12: loss=0.92092
Epoch 13: loss=0.91166
Epoch 14: loss=0.88618
Epoch 15: loss=0.88592
Epoch 16: loss=0.90464
Epoch 17: loss=0.89131
Epoch 18: loss=0.90706
Epoch 19: loss=0.90734
Epoch 20: loss=0.87285
Epoch 21: loss=0.87794
Epoch 22: loss=0.85561
Epoch 23: loss=0.87513
Epoch 24: loss=0.88077
Epoch 25: loss=0.88516
Epoch 26: loss=0.88471
Epoch 27: loss=0.86626
Epoch 28: loss=0.89861
Epoch 29: loss=0.89086
Epoch 30: loss=0.89352
Epoch 31: loss=0.91470
Epoch 32: loss=0.88078
Epoch 33: loss=0.89205
Epoch 34: loss=0.89189
Epoch 35: loss=0.88498
Epoch 36: loss=0.89690
Epoch 37: loss=0.88749
Epoch 38: loss=0.88576
Epoch 39: loss=0.87697
Epoch 40: loss=0.86452
Epoch 41: loss=0.87234
Epoch 42: loss=0.87998
Epoch 43: loss=0.87686
Epoch 44: loss=0.86785
Epoch 45: loss=0.85631
Epoch 46: loss=0.83402
Epoch 47: loss=0.84086
Epoch 48: loss=0.84455
Epoch 49: loss=0.85464
Epoch 50: loss=0.85649
Epoch 51: loss=0.86378
Epoch 52: loss=0.86107
Epoch 53: loss=0.84277
Epoch 54: loss=0.83871
Epoch 55: loss=0.84596
Epoch 56: loss=0.85855
Epoch 57: loss=0.83225
Epoch 58: loss=0.83800
Epoch 59: loss=0.83839
Epoch 60: loss=0.83116
Epoch 61: loss=0.84964
Epoch 62: loss=0.83615
Epoch 63: loss=0.83799
Epoch 64: loss=0.84763
Epoch 65: loss=0.84228
Epoch 66: loss=0.83802
Epoch 67: loss=0.83436
Epoch 68: loss=0.84379
Epoch 69: loss=0.81978
Epoch 70: loss=0.83462
Epoch 71: loss=0.83542
Epoch 72: loss=0.83765
Epoch 73: loss=0.84075
Epoch 74: loss=0.85076
Epoch 75: loss=0.85515
Epoch 76: loss=0.82391
Epoch 77: loss=0.80718
Epoch 78: loss=0.81681
Epoch 79: loss=0.82422
Epoch 80: loss=0.81881
Epoch 81: loss=0.84201
Epoch 82: loss=0.85118
Epoch 83: loss=0.84425
Epoch 84: loss=0.82809
Epoch 85: loss=0.83248
Epoch 86: loss=0.83333
Epoch 87: loss=0.82655
Epoch 88: loss=0.82758
Epoch 89: loss=0.83197
Epoch 90: loss=0.82746
Epoch 91: loss=0.83371
Epoch 92: loss=0.83096
Epoch 93: loss=0.84603
Epoch 94: loss=0.83257
Epoch 95: loss=0.83676
Epoch 96: loss=0.82881
Epoch 97: loss=0.82438
Epoch 98: loss=0.84641
Epoch 99: loss=0.82564
Epoch 100: loss=0.83907
Epoch 101: loss=0.82198
Epoch 102: loss=0.82789
Epoch 103: loss=0.81916
Epoch 104: loss=0.83845
Epoch 105: loss=0.85904
Epoch 106: loss=0.82537
Epoch 107: loss=0.81947
Epoch 108: loss=0.85928
Epoch 109: loss=0.82229
Epoch 110: loss=0.82664
Epoch 111: loss=0.83227
Epoch 112: loss=0.81937
Epoch 113: loss=0.84139
Epoch 114: loss=0.80799
Epoch 115: loss=0.80104
Epoch 116: loss=0.80059
Epoch 117: loss=0.80940
Epoch 118: loss=0.82070
Epoch 119: loss=0.83373
Epoch 120: loss=0.81715
Epoch 121: loss=0.81498
Epoch 122: loss=0.80730
Epoch 123: loss=0.82637
Epoch 124: loss=0.83021
Epoch 125: loss=0.82464
Epoch 126: loss=0.81400
Epoch 127: loss=0.81983
Epoch 128: loss=0.81633
Epoch 129: loss=0.81608
Epoch 130: loss=0.82128
Epoch 131: loss=0.83618
Epoch 132: loss=0.82712
Epoch 133: loss=0.81091
Epoch 134: loss=0.81741
Epoch 135: loss=0.82030
Epoch 136: loss=0.79625
Epoch 137: loss=0.81449
Epoch 138: loss=0.79789
Epoch 139: loss=0.79097
Epoch 140: loss=0.79417
Epoch 141: loss=0.80413
Epoch 142: loss=0.81703
Epoch 143: loss=0.82081
Epoch 144: loss=0.80321
Epoch 145: loss=0.80234
Epoch 146: loss=0.82160
Epoch 147: loss=0.82473
Epoch 148: loss=0.80836
Epoch 149: loss=0.80884
Epoch 150: loss=0.80718
Epoch 151: loss=0.83084
Epoch 152: loss=0.81340
Epoch 153: loss=0.81643
Epoch 154: loss=0.80253
Epoch 155: loss=0.79840
Epoch 156: loss=0.80642
Epoch 157: loss=0.80906
Epoch 158: loss=0.81661
Epoch 159: loss=0.80282
Epoch 160: loss=0.79924
Epoch 161: loss=0.81424
Epoch 162: loss=0.79989
Epoch 163: loss=0.82268
Epoch 164: loss=0.81039
Epoch 165: loss=0.81027
Epoch 166: loss=0.80646
Epoch 167: loss=0.79319
Epoch 168: loss=0.80820
Epoch 169: loss=0.82660
Epoch 170: loss=0.81563
Epoch 171: loss=0.80570
Epoch 172: loss=0.82209
Epoch 173: loss=0.78971
Epoch 174: loss=0.77326
Epoch 175: loss=0.79677
Epoch 176: loss=0.80608
Epoch 177: loss=0.79824
Epoch 178: loss=0.79157
Epoch 179: loss=0.80066
Epoch 180: loss=0.81581
Epoch 181: loss=0.81779
Epoch 182: loss=0.80894
Epoch 183: loss=0.79832
Epoch 184: loss=0.79778
Epoch 185: loss=0.79342
Epoch 186: loss=0.79772
Epoch 187: loss=0.79783
Epoch 188: loss=0.78737
Epoch 189: loss=0.81494
Epoch 190: loss=0.81134
Epoch 191: loss=0.80218
Epoch 192: loss=0.78689
Epoch 193: loss=0.78948
Epoch 194: loss=0.78078
Epoch 195: loss=0.79466
Epoch 196: loss=0.83877
Epoch 197: loss=0.81757
Epoch 198: loss=0.80457
Epoch 199: loss=0.79991
Epoch 200: loss=0.80423
Training accuracy: 0.821
Test accuracy: 0.552

File list dumped

Saved in file
