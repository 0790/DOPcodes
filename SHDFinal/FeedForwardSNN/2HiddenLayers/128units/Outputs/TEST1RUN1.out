/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/128units/dataset/shddataset/
2 layered 128 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
Epoch 1: loss=16.29240
Epoch 2: loss=8.59305
Epoch 3: loss=5.94264
Epoch 4: loss=4.60769
Epoch 5: loss=3.93372
Epoch 6: loss=3.59088
Epoch 7: loss=3.36652
Epoch 8: loss=3.25412
Epoch 9: loss=3.15190
Epoch 10: loss=3.12074
Trained for 10 epochs
Training accuracy: 0.107
Epoch 1: loss=3.05487
Epoch 2: loss=3.01089
Epoch 3: loss=2.95590
Epoch 4: loss=2.93598
Epoch 5: loss=2.90950
Epoch 6: loss=2.89870
Epoch 7: loss=2.87683
Epoch 8: loss=2.84817
Epoch 9: loss=2.82159
Epoch 10: loss=2.80439
Epoch 11: loss=2.79770
Epoch 12: loss=2.78951
Epoch 13: loss=2.77984
Epoch 14: loss=2.76483
Epoch 15: loss=2.74609
Epoch 16: loss=2.74287
Epoch 17: loss=2.74301
Epoch 18: loss=2.75819
Epoch 19: loss=2.74799
Epoch 20: loss=2.73284
Epoch 21: loss=2.74553
Epoch 22: loss=2.73783
Epoch 23: loss=2.73623
Epoch 24: loss=2.72284
Epoch 25: loss=2.73389
Epoch 26: loss=2.72742
Epoch 27: loss=2.70616
Epoch 28: loss=2.69601
Epoch 29: loss=2.68832
Epoch 30: loss=2.67853
Epoch 31: loss=2.66014
Epoch 32: loss=2.65007
Epoch 33: loss=2.62610
Epoch 34: loss=2.60272
Epoch 35: loss=2.58197
Epoch 36: loss=2.57209
Epoch 37: loss=2.56090
Epoch 38: loss=2.55145
Epoch 39: loss=2.53056
Epoch 40: loss=2.51735
Epoch 41: loss=2.50663
Epoch 42: loss=2.49938
Epoch 43: loss=2.47791
Epoch 44: loss=2.46045
Epoch 45: loss=2.45868
Epoch 46: loss=2.45226
Epoch 47: loss=2.44773
Epoch 48: loss=2.45544
Epoch 49: loss=2.43891
Epoch 50: loss=2.43363
Epoch 51: loss=2.43157
Epoch 52: loss=2.44051
Epoch 53: loss=2.42200
Epoch 54: loss=2.41780
Epoch 55: loss=2.41455
Epoch 56: loss=2.40378
Epoch 57: loss=2.37888
Epoch 58: loss=2.36098
Epoch 59: loss=2.34893
Epoch 60: loss=2.35208
Epoch 61: loss=2.34273
Epoch 62: loss=2.34054
Epoch 63: loss=2.34645
Epoch 64: loss=2.33346
Epoch 65: loss=2.33660
Epoch 66: loss=2.32188
Epoch 67: loss=2.29799
Epoch 68: loss=2.29471
Epoch 69: loss=2.30057
Epoch 70: loss=2.28586
Epoch 71: loss=2.26366
Epoch 72: loss=2.24644
Epoch 73: loss=2.24133
Epoch 74: loss=2.22360
Epoch 75: loss=2.21519
Epoch 76: loss=2.19327
Epoch 77: loss=2.17856
Epoch 78: loss=2.18405
Epoch 79: loss=2.17685
Epoch 80: loss=2.14430
Epoch 81: loss=2.14099
Epoch 82: loss=2.14643
Epoch 83: loss=2.13548
Epoch 84: loss=2.12895
Epoch 85: loss=2.12208
Epoch 86: loss=2.15008
Epoch 87: loss=2.15624
Epoch 88: loss=2.14144
Epoch 89: loss=2.11002
Epoch 90: loss=2.09279
Epoch 91: loss=2.07592
Epoch 92: loss=2.08107
Epoch 93: loss=2.08673
Epoch 94: loss=2.09616
Epoch 95: loss=2.09147
Epoch 96: loss=2.06959
Epoch 97: loss=2.06961
Epoch 98: loss=2.06223
Epoch 99: loss=2.05114
Epoch 100: loss=2.03025
Epoch 101: loss=2.01144
Epoch 102: loss=2.02289
Epoch 103: loss=2.01933
Epoch 104: loss=2.04094
Epoch 105: loss=2.02645
Epoch 106: loss=2.00623
Epoch 107: loss=2.00690
Epoch 108: loss=1.98102
Epoch 109: loss=1.97432
Epoch 110: loss=1.98504
Epoch 111: loss=1.96824
Epoch 112: loss=1.97148
Epoch 113: loss=1.94549
Epoch 114: loss=1.93415
Epoch 115: loss=1.94126
Epoch 116: loss=1.91722
Epoch 117: loss=1.91866
Epoch 118: loss=1.89697
Epoch 119: loss=1.89401
Epoch 120: loss=1.89530
Epoch 121: loss=1.88955
Epoch 122: loss=1.89218
Epoch 123: loss=1.89031
Epoch 124: loss=1.86381
Epoch 125: loss=1.86519
Epoch 126: loss=1.85540
Epoch 127: loss=1.84195
Epoch 128: loss=1.82695
Epoch 129: loss=1.81035
Epoch 130: loss=1.79751
Epoch 131: loss=1.79901
Epoch 132: loss=1.79698
Epoch 133: loss=1.77927
Epoch 134: loss=1.78299
Epoch 135: loss=1.78573
Epoch 136: loss=1.79408
Epoch 137: loss=1.77175
Epoch 138: loss=1.75737
Epoch 139: loss=1.74611
Epoch 140: loss=1.76815
Epoch 141: loss=1.73775
Epoch 142: loss=1.72457
Epoch 143: loss=1.73472
Epoch 144: loss=1.71637
Epoch 145: loss=1.72570
Epoch 146: loss=1.71572
Epoch 147: loss=1.70753
Epoch 148: loss=1.70589
Epoch 149: loss=1.69106
Epoch 150: loss=1.68843
Epoch 151: loss=1.66881
Epoch 152: loss=1.67024
Epoch 153: loss=1.65627
Epoch 154: loss=1.66241
Epoch 155: loss=1.66102
Epoch 156: loss=1.66183
Epoch 157: loss=1.63663
Epoch 158: loss=1.63467
Epoch 159: loss=1.65050
Epoch 160: loss=1.63463
Epoch 161: loss=1.63024
Epoch 162: loss=1.61781
Epoch 163: loss=1.61801
Epoch 164: loss=1.61509
Epoch 165: loss=1.61814
Epoch 166: loss=1.61230
Epoch 167: loss=1.60642
Epoch 168: loss=1.60003
Epoch 169: loss=1.60037
Epoch 170: loss=1.58718
Epoch 171: loss=1.58292
Epoch 172: loss=1.56992
Epoch 173: loss=1.58605
Epoch 174: loss=1.56535
Epoch 175: loss=1.57129
Epoch 176: loss=1.58699
Epoch 177: loss=1.57491
Epoch 178: loss=1.57143
Epoch 179: loss=1.58300
Epoch 180: loss=1.58538
Epoch 181: loss=1.56421
Epoch 182: loss=1.56099
Epoch 183: loss=1.58660
Epoch 184: loss=1.58110
Epoch 185: loss=1.56692
Epoch 186: loss=1.56049
Epoch 187: loss=1.55264
Epoch 188: loss=1.55862
Epoch 189: loss=1.54182
Epoch 190: loss=1.53845
Epoch 191: loss=1.51662
Epoch 192: loss=1.52923
Epoch 193: loss=1.51535
Epoch 194: loss=1.50836
Epoch 195: loss=1.52628
Epoch 196: loss=1.52628
Epoch 197: loss=1.52319
Epoch 198: loss=1.51743
Epoch 199: loss=1.52000
Epoch 200: loss=1.51615
Training accuracy: 0.555
Test accuracy: 0.485

File list dumped

Saved in file
