/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/128units/dataset/shddataset/
2 layered 128 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
The file is present.
Epoch 1: loss=1.51073
Epoch 2: loss=1.51546
Epoch 3: loss=1.48275
Epoch 4: loss=1.46440
Epoch 5: loss=1.48422
Epoch 6: loss=1.48962
Epoch 7: loss=1.46780
Epoch 8: loss=1.47421
Epoch 9: loss=1.48689
Epoch 10: loss=1.46843
Trained for 10 epochs
Training accuracy: 0.579
Epoch 1: loss=1.46689
Epoch 2: loss=1.47415
Epoch 3: loss=1.46642
Epoch 4: loss=1.46717
Epoch 5: loss=1.46829
Epoch 6: loss=1.45454
Epoch 7: loss=1.45427
Epoch 8: loss=1.45203
Epoch 9: loss=1.44314
Epoch 10: loss=1.44944
Epoch 11: loss=1.44024
Epoch 12: loss=1.43520
Epoch 13: loss=1.44674
Epoch 14: loss=1.44680
Epoch 15: loss=1.43199
Epoch 16: loss=1.43603
Epoch 17: loss=1.45709
Epoch 18: loss=1.43137
Epoch 19: loss=1.42607
Epoch 20: loss=1.43543
Epoch 21: loss=1.43074
Epoch 22: loss=1.43639
Epoch 23: loss=1.42954
Epoch 24: loss=1.42249
Epoch 25: loss=1.45358
Epoch 26: loss=1.44947
Epoch 27: loss=1.44339
Epoch 28: loss=1.41067
Epoch 29: loss=1.40562
Epoch 30: loss=1.40457
Epoch 31: loss=1.40719
Epoch 32: loss=1.42393
Epoch 33: loss=1.41234
Epoch 34: loss=1.41600
Epoch 35: loss=1.41152
Epoch 36: loss=1.39599
Epoch 37: loss=1.40955
Epoch 38: loss=1.41425
Epoch 39: loss=1.40765
Epoch 40: loss=1.42418
Epoch 41: loss=1.41306
Epoch 42: loss=1.40960
Epoch 43: loss=1.40526
Epoch 44: loss=1.39868
Epoch 45: loss=1.36637
Epoch 46: loss=1.37224
Epoch 47: loss=1.37382
Epoch 48: loss=1.40680
Epoch 49: loss=1.39703
Epoch 50: loss=1.37953
Epoch 51: loss=1.39547
Epoch 52: loss=1.40300
Epoch 53: loss=1.39179
Epoch 54: loss=1.39778
Epoch 55: loss=1.40128
Epoch 56: loss=1.37540
Epoch 57: loss=1.37998
Epoch 58: loss=1.38187
Epoch 59: loss=1.36309
Epoch 60: loss=1.35595
Epoch 61: loss=1.37241
Epoch 62: loss=1.34785
Epoch 63: loss=1.35049
Epoch 64: loss=1.34916
Epoch 65: loss=1.34492
Epoch 66: loss=1.32799
Epoch 67: loss=1.34153
Epoch 68: loss=1.34715
Epoch 69: loss=1.34631
Epoch 70: loss=1.34915
Epoch 71: loss=1.33353
Epoch 72: loss=1.32243
Epoch 73: loss=1.33575
Epoch 74: loss=1.32882
Epoch 75: loss=1.33038
Epoch 76: loss=1.31555
Epoch 77: loss=1.30711
Epoch 78: loss=1.32316
Epoch 79: loss=1.31921
Epoch 80: loss=1.32705
Epoch 81: loss=1.31579
Epoch 82: loss=1.31223
Epoch 83: loss=1.30066
Epoch 84: loss=1.29553
Epoch 85: loss=1.29799
Epoch 86: loss=1.30447
Epoch 87: loss=1.28781
Epoch 88: loss=1.29616
Epoch 89: loss=1.28645
Epoch 90: loss=1.28249
Epoch 91: loss=1.28876
Epoch 92: loss=1.27223
Epoch 93: loss=1.28020
Epoch 94: loss=1.27488
Epoch 95: loss=1.27615
Epoch 96: loss=1.25428
Epoch 97: loss=1.26634
Epoch 98: loss=1.27119
Epoch 99: loss=1.26882
Epoch 100: loss=1.24792
Epoch 101: loss=1.26945
Epoch 102: loss=1.26961
Epoch 103: loss=1.26638
Epoch 104: loss=1.26246
Epoch 105: loss=1.25522
Epoch 106: loss=1.25426
Epoch 107: loss=1.24783
Epoch 108: loss=1.24084
Epoch 109: loss=1.25734
Epoch 110: loss=1.24625
Epoch 111: loss=1.23978
Epoch 112: loss=1.25033
Epoch 113: loss=1.23875
Epoch 114: loss=1.22806
Epoch 115: loss=1.23297
Epoch 116: loss=1.23037
Epoch 117: loss=1.22520
Epoch 118: loss=1.22289
Epoch 119: loss=1.21860
Epoch 120: loss=1.22684
Epoch 121: loss=1.23745
Epoch 122: loss=1.23525
Epoch 123: loss=1.23823
Epoch 124: loss=1.23408
Epoch 125: loss=1.24062
Epoch 126: loss=1.22042
Epoch 127: loss=1.21242
Epoch 128: loss=1.21558
Epoch 129: loss=1.21005
Epoch 130: loss=1.20919
Epoch 131: loss=1.20487
Epoch 132: loss=1.21551
Epoch 133: loss=1.20651
Epoch 134: loss=1.21052
Epoch 135: loss=1.19665
Epoch 136: loss=1.20319
Epoch 137: loss=1.19596
Epoch 138: loss=1.18937
Epoch 139: loss=1.18443
Epoch 140: loss=1.17911
Epoch 141: loss=1.17750
Epoch 142: loss=1.17787
Epoch 143: loss=1.18594
Epoch 144: loss=1.18448
Epoch 145: loss=1.16991
Epoch 146: loss=1.17464
Epoch 147: loss=1.18150
Epoch 148: loss=1.16695
Epoch 149: loss=1.16818
Epoch 150: loss=1.17041
Epoch 151: loss=1.15715
Epoch 152: loss=1.17595
Epoch 153: loss=1.19415
Epoch 154: loss=1.18508
Epoch 155: loss=1.17257
Epoch 156: loss=1.17584
Epoch 157: loss=1.17448
Epoch 158: loss=1.15946
Epoch 159: loss=1.14964
Epoch 160: loss=1.17802
Epoch 161: loss=1.15843
Epoch 162: loss=1.15416
Epoch 163: loss=1.14153
Epoch 164: loss=1.14120
Epoch 165: loss=1.15381
Epoch 166: loss=1.15577
Epoch 167: loss=1.15921
Epoch 168: loss=1.15772
Epoch 169: loss=1.14227
Epoch 170: loss=1.15288
Epoch 171: loss=1.16262
Epoch 172: loss=1.15564
Epoch 173: loss=1.13782
Epoch 174: loss=1.14456
Epoch 175: loss=1.15171
Epoch 176: loss=1.14706
Epoch 177: loss=1.12295
Epoch 178: loss=1.12346
Epoch 179: loss=1.12466
Epoch 180: loss=1.12249
Epoch 181: loss=1.12491
Epoch 182: loss=1.11801
Epoch 183: loss=1.12834
Epoch 184: loss=1.12029
Epoch 185: loss=1.13264
Epoch 186: loss=1.12491
Epoch 187: loss=1.12681
Epoch 188: loss=1.12825
Epoch 189: loss=1.10682
Epoch 190: loss=1.10913
Epoch 191: loss=1.11182
Epoch 192: loss=1.12410
Epoch 193: loss=1.11543
Epoch 194: loss=1.11508
Epoch 195: loss=1.12261
Epoch 196: loss=1.13313
Epoch 197: loss=1.12132
Epoch 198: loss=1.11881
Epoch 199: loss=1.11849
Epoch 200: loss=1.11012
Training accuracy: 0.703
Test accuracy: 0.553

File list dumped

Saved in file
