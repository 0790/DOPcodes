/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHDFinal/FeedForwardSNN/2HiddenLayers/128units/dataset/shddataset/
2 layered 128 unit SNN made weight variables and loss histogram
made weight variables and loss histogram
The file is present.
Epoch 1: loss=0.98407
Epoch 2: loss=1.00046
Epoch 3: loss=0.98644
Epoch 4: loss=0.99082
Epoch 5: loss=0.99835
Epoch 6: loss=0.98351
Epoch 7: loss=0.99477
Epoch 8: loss=1.00310
Epoch 9: loss=1.01013
Epoch 10: loss=1.01807
Trained for 10 epochs
Training accuracy: 0.741
Epoch 1: loss=1.00162
Epoch 2: loss=1.01035
Epoch 3: loss=1.00148
Epoch 4: loss=0.99383
Epoch 5: loss=1.02565
Epoch 6: loss=1.01528
Epoch 7: loss=0.98876
Epoch 8: loss=1.00450
Epoch 9: loss=1.00332
Epoch 10: loss=1.02387
Epoch 11: loss=1.04313
Epoch 12: loss=1.02957
Epoch 13: loss=1.05211
Epoch 14: loss=1.09482
Epoch 15: loss=1.10232
Epoch 16: loss=1.09184
Epoch 17: loss=1.11615
Epoch 18: loss=1.11573
Epoch 19: loss=1.12333
Epoch 20: loss=1.13000
Epoch 21: loss=1.12362
Epoch 22: loss=1.09264
Epoch 23: loss=1.09536
Epoch 24: loss=1.08499
Epoch 25: loss=1.08081
Epoch 26: loss=1.08482
Epoch 27: loss=1.07036
Epoch 28: loss=1.07027
Epoch 29: loss=1.06807
Epoch 30: loss=1.07484
Epoch 31: loss=1.09287
Epoch 32: loss=1.07910
Epoch 33: loss=1.07748
Epoch 34: loss=1.04877
Epoch 35: loss=1.04651
Epoch 36: loss=1.04086
Epoch 37: loss=1.05137
Epoch 38: loss=1.04543
Epoch 39: loss=1.03704
Epoch 40: loss=1.05690
Epoch 41: loss=1.06771
Epoch 42: loss=1.04439
Epoch 43: loss=1.04465
Epoch 44: loss=1.04941
Epoch 45: loss=1.05045
Epoch 46: loss=1.04786
Epoch 47: loss=1.05309
Epoch 48: loss=1.06066
Epoch 49: loss=1.04041
Epoch 50: loss=1.01063
Epoch 51: loss=1.03857
Epoch 52: loss=1.03800
Epoch 53: loss=1.01097
Epoch 54: loss=1.03139
Epoch 55: loss=1.02871
Epoch 56: loss=1.02321
Epoch 57: loss=1.00803
Epoch 58: loss=1.01739
Epoch 59: loss=0.99157
Epoch 60: loss=1.03071
Epoch 61: loss=1.00631
Epoch 62: loss=1.00254
Epoch 63: loss=0.99284
Epoch 64: loss=1.00588
Epoch 65: loss=1.00031
Epoch 66: loss=1.02718
Epoch 67: loss=0.98490
Epoch 68: loss=0.99837
Epoch 69: loss=1.00450
Epoch 70: loss=0.98905
Epoch 71: loss=0.97945
Epoch 72: loss=0.99280
Epoch 73: loss=0.99912
Epoch 74: loss=0.98356
Epoch 75: loss=0.96957
Epoch 76: loss=0.98463
Epoch 77: loss=0.99071
Epoch 78: loss=0.99318
Epoch 79: loss=0.99118
Epoch 80: loss=0.98728
Epoch 81: loss=0.99914
Epoch 82: loss=0.98051
Epoch 83: loss=0.98625
Epoch 84: loss=0.98303
Epoch 85: loss=0.96762
Epoch 86: loss=0.96228
Epoch 87: loss=0.95335
Epoch 88: loss=0.95814
Epoch 89: loss=0.95062
Epoch 90: loss=0.93174
Epoch 91: loss=0.93859
Epoch 92: loss=0.94322
Epoch 93: loss=0.94468
Epoch 94: loss=0.94294
Epoch 95: loss=0.94135
Epoch 96: loss=0.93242
Epoch 97: loss=0.94263
Epoch 98: loss=0.97482
Epoch 99: loss=0.95126
Epoch 100: loss=0.95254
Epoch 101: loss=0.95458
Epoch 102: loss=0.94982
Epoch 103: loss=0.97527
Epoch 104: loss=0.95056
Epoch 105: loss=0.96359
Epoch 106: loss=0.94003
Epoch 107: loss=0.94794
Epoch 108: loss=0.93855
Epoch 109: loss=0.92990
Epoch 110: loss=0.94889
Epoch 111: loss=0.93795
Epoch 112: loss=0.93998
Epoch 113: loss=0.95335
Epoch 114: loss=0.94519
Epoch 115: loss=0.93233
Epoch 116: loss=0.93275
Epoch 117: loss=0.93515
Epoch 118: loss=0.94867
Epoch 119: loss=0.93413
Epoch 120: loss=0.91220
Epoch 121: loss=0.90859
Epoch 122: loss=0.92401
Epoch 123: loss=0.91686
Epoch 124: loss=0.92263
Epoch 125: loss=0.92859
Epoch 126: loss=0.92307
Epoch 127: loss=0.93102
Epoch 128: loss=0.92638
Epoch 129: loss=0.91635
Epoch 130: loss=0.91644
Epoch 131: loss=0.90550
Epoch 132: loss=0.93645
Epoch 133: loss=0.92891
Epoch 134: loss=0.92140
Epoch 135: loss=0.91996
Epoch 136: loss=0.93190
Epoch 137: loss=0.91075
Epoch 138: loss=0.93659
Epoch 139: loss=0.91280
Epoch 140: loss=0.90911
Epoch 141: loss=0.92508
Epoch 142: loss=0.94180
Epoch 143: loss=0.92666
Epoch 144: loss=0.93421
Epoch 145: loss=0.94247
Epoch 146: loss=0.94322
Epoch 147: loss=0.91771
Epoch 148: loss=0.93816
Epoch 149: loss=0.93717
Epoch 150: loss=0.93204
Epoch 151: loss=0.93348
Epoch 152: loss=0.91597
Epoch 153: loss=0.90916
Epoch 154: loss=0.89403
Epoch 155: loss=0.89640
Epoch 156: loss=0.90270
Epoch 157: loss=0.87419
Epoch 158: loss=0.88489
Epoch 159: loss=0.87976
Epoch 160: loss=0.87881
Epoch 161: loss=0.88148
Epoch 162: loss=0.89447
Epoch 163: loss=0.87681
Epoch 164: loss=0.89355
Epoch 165: loss=0.88662
Epoch 166: loss=0.87713
Epoch 167: loss=0.88703
Epoch 168: loss=0.85756
Epoch 169: loss=0.87331
Epoch 170: loss=0.88092
Epoch 171: loss=0.87712
Epoch 172: loss=0.88194
Epoch 173: loss=0.90600
Epoch 174: loss=0.87920
Epoch 175: loss=0.87334
Epoch 176: loss=0.86968
Epoch 177: loss=0.86374
Epoch 178: loss=0.89092
Epoch 179: loss=0.89995
Epoch 180: loss=0.88404
Epoch 181: loss=0.89785
Epoch 182: loss=0.89756
Epoch 183: loss=0.91748
Epoch 184: loss=0.90930
Epoch 185: loss=0.91075
Epoch 186: loss=0.90223
Epoch 187: loss=0.92169
Epoch 188: loss=0.89811
Epoch 189: loss=0.90283
Epoch 190: loss=0.93003
Epoch 191: loss=0.95623
Epoch 192: loss=0.94370
Epoch 193: loss=0.95970
Epoch 194: loss=0.94434
Epoch 195: loss=0.91041
Epoch 196: loss=0.92557
Epoch 197: loss=0.92575
Epoch 198: loss=0.91627
Epoch 199: loss=0.91294
Epoch 200: loss=0.94658
Training accuracy: 0.760
Test accuracy: 0.546

File list dumped

Saved in file
