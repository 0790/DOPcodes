/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHD/dataset/shddataset/
init done
Epoch 1: loss=3.37292
Epoch 2: loss=2.91486
Epoch 3: loss=2.85681
Epoch 4: loss=2.80158
Epoch 5: loss=2.74599
Epoch 6: loss=2.68601
Epoch 7: loss=2.62461
Epoch 8: loss=2.55323
Epoch 9: loss=2.47877
Epoch 10: loss=2.39748
Epoch 11: loss=2.31196
Epoch 12: loss=2.22776
Epoch 13: loss=2.16355
Epoch 14: loss=2.09087
Epoch 15: loss=2.02861
Epoch 16: loss=1.96966
Epoch 17: loss=1.91532
Epoch 18: loss=1.86318
Epoch 19: loss=1.81869
Epoch 20: loss=1.76782
Epoch 21: loss=1.72112
Epoch 22: loss=1.68619
Epoch 23: loss=1.64134
Epoch 24: loss=1.60899
Epoch 25: loss=1.58085
Epoch 26: loss=1.54411
Epoch 27: loss=1.50604
Epoch 28: loss=1.47055
Epoch 29: loss=1.43997
Epoch 30: loss=1.42137
Epoch 31: loss=1.38997
Epoch 32: loss=1.36496
Epoch 33: loss=1.33630
Epoch 34: loss=1.31049
Epoch 35: loss=1.28801
Epoch 36: loss=1.26156
Epoch 37: loss=1.23649
Epoch 38: loss=1.21898
Epoch 39: loss=1.18918
Epoch 40: loss=1.17404
Epoch 41: loss=1.14967
Epoch 42: loss=1.13143
Epoch 43: loss=1.11564
Epoch 44: loss=1.10189
Epoch 45: loss=1.07517
Epoch 46: loss=1.07224
Epoch 47: loss=1.04259
Epoch 48: loss=1.02558
Epoch 49: loss=1.00711
Epoch 50: loss=1.00168
Epoch 51: loss=0.97076
Epoch 52: loss=0.96128
Epoch 53: loss=0.95376
Epoch 54: loss=0.93059
Epoch 55: loss=0.90981
Epoch 56: loss=0.89900
Epoch 57: loss=0.88660
Epoch 58: loss=0.87393
Epoch 59: loss=0.86568
Epoch 60: loss=0.85816
Epoch 61: loss=0.85125
Epoch 62: loss=0.83395
Epoch 63: loss=0.81929
Epoch 64: loss=0.81521
Epoch 65: loss=0.80054
Epoch 66: loss=0.79109
Epoch 67: loss=0.77893
Epoch 68: loss=0.75961
Epoch 69: loss=0.75414
Epoch 70: loss=0.74559
Epoch 71: loss=0.73530
Epoch 72: loss=0.72868
Epoch 73: loss=0.71761
Epoch 74: loss=0.70952
Epoch 75: loss=0.69597
Epoch 76: loss=0.68953
Epoch 77: loss=0.68864
Epoch 78: loss=0.68558
Epoch 79: loss=0.66697
Epoch 80: loss=0.66258
Epoch 81: loss=0.65824
Epoch 82: loss=0.64657
Epoch 83: loss=0.64568
Epoch 84: loss=0.63640
Epoch 85: loss=0.62638
Epoch 86: loss=0.61382
Epoch 87: loss=0.60738
Epoch 88: loss=0.60278
Epoch 89: loss=0.59442
Epoch 90: loss=0.59086
Epoch 91: loss=0.58561
Epoch 92: loss=0.57374
Epoch 93: loss=0.56720
Epoch 94: loss=0.56533
Epoch 95: loss=0.56004
Epoch 96: loss=0.55648
Epoch 97: loss=0.54311
Epoch 98: loss=0.54410
Epoch 99: loss=0.53313
Epoch 100: loss=0.53221
Epoch 101: loss=0.51854
Epoch 102: loss=0.51798
Epoch 103: loss=0.51439
Epoch 104: loss=0.50846
Epoch 105: loss=0.49794
Epoch 106: loss=0.48775
Epoch 107: loss=0.48829
Epoch 108: loss=0.48059
Epoch 109: loss=0.48065
Epoch 110: loss=0.47887
Epoch 111: loss=0.46779
Epoch 112: loss=0.46687
Epoch 113: loss=0.46801
Epoch 114: loss=0.45665
Epoch 115: loss=0.45096
Epoch 116: loss=0.44627
Epoch 117: loss=0.44872
Epoch 118: loss=0.44655
Epoch 119: loss=0.43608
Epoch 120: loss=0.43521
Epoch 121: loss=0.42579
Epoch 122: loss=0.42408
Epoch 123: loss=0.41603
Epoch 124: loss=0.41782
Epoch 125: loss=0.41412
Epoch 126: loss=0.40705
Epoch 127: loss=0.41405
Epoch 128: loss=0.40721
Epoch 129: loss=0.40269
Epoch 130: loss=0.39578
Epoch 131: loss=0.39388
Epoch 132: loss=0.38530
Epoch 133: loss=0.38312
Epoch 134: loss=0.38806
Epoch 135: loss=0.37644
Epoch 136: loss=0.36701
Epoch 137: loss=0.36984
Epoch 138: loss=0.36850
Epoch 139: loss=0.36223
Epoch 140: loss=0.36110
Epoch 141: loss=0.36015
Epoch 142: loss=0.35770
Epoch 143: loss=0.35206
Epoch 144: loss=0.35331
Epoch 145: loss=0.34654
Epoch 146: loss=0.34351
Epoch 147: loss=0.34580
Epoch 148: loss=0.33991
Epoch 149: loss=0.32950
Epoch 150: loss=0.32586
Epoch 151: loss=0.32441
Epoch 152: loss=0.32198
Epoch 153: loss=0.32023
Epoch 154: loss=0.31730
Epoch 155: loss=0.31421
Epoch 156: loss=0.31462
Epoch 157: loss=0.31216
Epoch 158: loss=0.30439
Epoch 159: loss=0.30763
Epoch 160: loss=0.30654
Epoch 161: loss=0.30608
Epoch 162: loss=0.29633
Epoch 163: loss=0.28773
Epoch 164: loss=0.29249
Epoch 165: loss=0.28725
Epoch 166: loss=0.28521
Epoch 167: loss=0.28534
Epoch 168: loss=0.28544
Epoch 169: loss=0.27946
Epoch 170: loss=0.28062
Epoch 171: loss=0.27583
Epoch 172: loss=0.26933
Epoch 173: loss=0.27705
Epoch 174: loss=0.27109
Epoch 175: loss=0.26591
Epoch 176: loss=0.26592
Epoch 177: loss=0.26247
Epoch 178: loss=0.26206
Epoch 179: loss=0.26114
Epoch 180: loss=0.26840
Epoch 181: loss=0.25285
Epoch 182: loss=0.25828
Epoch 183: loss=0.24797
Epoch 184: loss=0.25018
Epoch 185: loss=0.24537
Epoch 186: loss=0.24603
Epoch 187: loss=0.24356
Epoch 188: loss=0.23971
Epoch 189: loss=0.23676
Epoch 190: loss=0.23693
Epoch 191: loss=0.23794
Epoch 192: loss=0.23305
Epoch 193: loss=0.23016
Epoch 194: loss=0.23262
Epoch 195: loss=0.23118
Epoch 196: loss=0.22473
Epoch 197: loss=0.22477
Epoch 198: loss=0.21806
Epoch 199: loss=0.22268
Epoch 200: loss=0.21364
Epoch 201: loss=0.21634
Epoch 202: loss=0.21187
Epoch 203: loss=0.21800
Epoch 204: loss=0.21459
Epoch 205: loss=0.21661
Epoch 206: loss=0.21019
Epoch 207: loss=0.20640
Epoch 208: loss=0.20663
Epoch 209: loss=0.21161
Epoch 210: loss=0.20625
Epoch 211: loss=0.19857
Epoch 212: loss=0.19972
Epoch 213: loss=0.19448
Epoch 214: loss=0.19602
Epoch 215: loss=0.19816
Epoch 216: loss=0.19328
Epoch 217: loss=0.19348
Epoch 218: loss=0.19303
Epoch 219: loss=0.19297
Epoch 220: loss=0.19069
Epoch 221: loss=0.18817
Epoch 222: loss=0.18753
Epoch 223: loss=0.18983
Epoch 224: loss=0.18872
Epoch 225: loss=0.18340
Epoch 226: loss=0.18103
Epoch 227: loss=0.17798
Epoch 228: loss=0.18112
Epoch 229: loss=0.17643
Epoch 230: loss=0.17348
Epoch 231: loss=0.17134
Epoch 232: loss=0.17057
Epoch 233: loss=0.17255
Epoch 234: loss=0.17155
Epoch 235: loss=0.17021
Epoch 236: loss=0.17075
Epoch 237: loss=0.16861
Epoch 238: loss=0.16713
Epoch 239: loss=0.16692
Epoch 240: loss=0.16634
Epoch 241: loss=0.16677
Epoch 242: loss=0.17327
Epoch 243: loss=0.16617
Epoch 244: loss=0.16358
Epoch 245: loss=0.16149
Epoch 246: loss=0.15710
Epoch 247: loss=0.15373
Epoch 248: loss=0.15444
Epoch 249: loss=0.15405
Epoch 250: loss=0.15879
Epoch 251: loss=0.15430
Epoch 252: loss=0.15447
Epoch 253: loss=0.15637
Epoch 254: loss=0.14710
Epoch 255: loss=0.14887
Epoch 256: loss=0.15331
Epoch 257: loss=0.14680
Epoch 258: loss=0.14574
Epoch 259: loss=0.14529
Epoch 260: loss=0.14550
Epoch 261: loss=0.14058
Epoch 262: loss=0.14441
Epoch 263: loss=0.14696
Epoch 264: loss=0.13961
Epoch 265: loss=0.14072
Epoch 266: loss=0.13592
Epoch 267: loss=0.13956
Epoch 268: loss=0.13818
Epoch 269: loss=0.13130
Epoch 270: loss=0.13373
Epoch 271: loss=0.13702
Epoch 272: loss=0.13407
Epoch 273: loss=0.13209
Epoch 274: loss=0.13593
Epoch 275: loss=0.13861
Epoch 276: loss=0.12658
Epoch 277: loss=0.12756
Epoch 278: loss=0.13164
Epoch 279: loss=0.13120
Epoch 280: loss=0.12726
Epoch 281: loss=0.12805
Epoch 282: loss=0.12669
Epoch 283: loss=0.12828
Epoch 284: loss=0.12607
Epoch 285: loss=0.12500
Epoch 286: loss=0.12392
Epoch 287: loss=0.12256
Epoch 288: loss=0.11959
Epoch 289: loss=0.12316
Epoch 290: loss=0.12405
Epoch 291: loss=0.11817
Epoch 292: loss=0.11804
Epoch 293: loss=0.11865
Epoch 294: loss=0.11746
Epoch 295: loss=0.11577
Epoch 296: loss=0.11440
Epoch 297: loss=0.11661
Epoch 298: loss=0.11744
Epoch 299: loss=0.11761
Epoch 300: loss=0.11559
Epoch 301: loss=0.11595
Epoch 302: loss=0.11122
Epoch 303: loss=0.11303
Epoch 304: loss=0.11266
Epoch 305: loss=0.11086
Epoch 306: loss=0.11102
Epoch 307: loss=0.10889
Epoch 308: loss=0.10692
Epoch 309: loss=0.10614
Epoch 310: loss=0.10612
Epoch 311: loss=0.10581
Epoch 312: loss=0.10683
Epoch 313: loss=0.10528
Epoch 314: loss=0.10721
Epoch 315: loss=0.10543
Epoch 316: loss=0.10586
Epoch 317: loss=0.10486
Epoch 318: loss=0.10198
Epoch 319: loss=0.10390
Epoch 320: loss=0.10057
Epoch 321: loss=0.09940
Epoch 322: loss=0.09972
Epoch 323: loss=0.10030
Epoch 324: loss=0.09861
Epoch 325: loss=0.09970
Epoch 326: loss=0.09945
Epoch 327: loss=0.09676
Epoch 328: loss=0.09497
Epoch 329: loss=0.09558
Epoch 330: loss=0.09548
Epoch 331: loss=0.09614
Epoch 332: loss=0.09790
Epoch 333: loss=0.10126
Epoch 334: loss=0.09581
Epoch 335: loss=0.09385
Epoch 336: loss=0.09322
Epoch 337: loss=0.09299
Epoch 338: loss=0.09203
Epoch 339: loss=0.09045
Epoch 340: loss=0.09138
Epoch 341: loss=0.09077
original_recur.py:67: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  labels_ = np.array(y,dtype=np.int)
Epoch 342: loss=0.09025
Epoch 343: loss=0.09003
Epoch 344: loss=0.09196
Epoch 345: loss=0.09028
Epoch 346: loss=0.08987
Epoch 347: loss=0.08862
Epoch 348: loss=0.08634
Epoch 349: loss=0.08575
Epoch 350: loss=0.08512
Epoch 351: loss=0.08893
Epoch 352: loss=0.08973
Epoch 353: loss=0.08639
Epoch 354: loss=0.08415
Epoch 355: loss=0.08513
Epoch 356: loss=0.08567
Epoch 357: loss=0.08466
Epoch 358: loss=0.08346
Epoch 359: loss=0.08603
Epoch 360: loss=0.08697
Epoch 361: loss=0.08366
Epoch 362: loss=0.08218
Epoch 363: loss=0.08463
Epoch 364: loss=0.08092
Epoch 365: loss=0.08097
Epoch 366: loss=0.08062
Epoch 367: loss=0.07909
Epoch 368: loss=0.07942
Epoch 369: loss=0.08222
Epoch 370: loss=0.08113
Epoch 371: loss=0.07945
Epoch 372: loss=0.08065
Epoch 373: loss=0.07923
Epoch 374: loss=0.07773
Epoch 375: loss=0.07658
Epoch 376: loss=0.07647
Epoch 377: loss=0.07649
Epoch 378: loss=0.07613
Epoch 379: loss=0.07603
Epoch 380: loss=0.07723
Epoch 381: loss=0.07616
Epoch 382: loss=0.07782
Epoch 383: loss=0.07746
Epoch 384: loss=0.07712
Epoch 385: loss=0.07534
Epoch 386: loss=0.07883
Epoch 387: loss=0.07744
Epoch 388: loss=0.07497
Epoch 389: loss=0.07265
Epoch 390: loss=0.07330
Epoch 391: loss=0.07449
Epoch 392: loss=0.07421
Epoch 393: loss=0.07195
Epoch 394: loss=0.07068
Epoch 395: loss=0.07023
Epoch 396: loss=0.06980
Epoch 397: loss=0.07047
Epoch 398: loss=0.06960
Epoch 399: loss=0.06897
Epoch 400: loss=0.06972
Epoch 401: loss=0.07017
Epoch 402: loss=0.07107
Epoch 403: loss=0.07026
Epoch 404: loss=0.06876
Epoch 405: loss=0.06759
Epoch 406: loss=0.06692
Epoch 407: loss=0.06638
Epoch 408: loss=0.06786
Epoch 409: loss=0.06673
Epoch 410: loss=0.06663
Epoch 411: loss=0.06832
Epoch 412: loss=0.06699
Epoch 413: loss=0.06601
Epoch 414: loss=0.06799
Epoch 415: loss=0.06684
Epoch 416: loss=0.06840
Epoch 417: loss=0.06755
Epoch 418: loss=0.06711
Epoch 419: loss=0.06479
Epoch 420: loss=0.06484
Epoch 421: loss=0.06338
Epoch 422: loss=0.06427
Epoch 423: loss=0.06317
Epoch 424: loss=0.06769
Epoch 425: loss=0.06623
Epoch 426: loss=0.06577
Epoch 427: loss=0.06431
Epoch 428: loss=0.06447
Epoch 429: loss=0.06132
Epoch 430: loss=0.06093
Epoch 431: loss=0.06120
Epoch 432: loss=0.06139
Epoch 433: loss=0.06158
Epoch 434: loss=0.06086
Epoch 435: loss=0.06166
Epoch 436: loss=0.06162
Epoch 437: loss=0.06102
Epoch 438: loss=0.06148
Epoch 439: loss=0.06053
Epoch 440: loss=0.05844
Epoch 441: loss=0.06253
Epoch 442: loss=0.06236
Epoch 443: loss=0.05957
Epoch 444: loss=0.05891
Epoch 445: loss=0.05860
Epoch 446: loss=0.06062
Epoch 447: loss=0.05939
Epoch 448: loss=0.05844
Epoch 449: loss=0.05950
Epoch 450: loss=0.05897
Epoch 451: loss=0.05868
Epoch 452: loss=0.05668
Epoch 453: loss=0.05611
Epoch 454: loss=0.05611
Epoch 455: loss=0.05603
Epoch 456: loss=0.05782
Epoch 457: loss=0.05810
Epoch 458: loss=0.05721
Epoch 459: loss=0.05988
Epoch 460: loss=0.05829
Epoch 461: loss=0.05537
Epoch 462: loss=0.05525
Epoch 463: loss=0.05575
Epoch 464: loss=0.05669
Epoch 465: loss=0.05710
Epoch 466: loss=0.05590
Epoch 467: loss=0.05432
Epoch 468: loss=0.05602
Epoch 469: loss=0.05506
Epoch 470: loss=0.05413
Epoch 471: loss=0.05502
Epoch 472: loss=0.05576
Epoch 473: loss=0.05434
Epoch 474: loss=0.05417
Epoch 475: loss=0.05442
Epoch 476: loss=0.05502
Epoch 477: loss=0.05292
Epoch 478: loss=0.05386
Epoch 479: loss=0.05443
Epoch 480: loss=0.05532
Epoch 481: loss=0.05409
Epoch 482: loss=0.05292
Epoch 483: loss=0.05173
Epoch 484: loss=0.05237
Epoch 485: loss=0.05220
Epoch 486: loss=0.05258
Epoch 487: loss=0.05547
Epoch 488: loss=0.05509
Epoch 489: loss=0.05404
Epoch 490: loss=0.05176
Epoch 491: loss=0.05183
Epoch 492: loss=0.05196
Epoch 493: loss=0.05230
Epoch 494: loss=0.05174
Epoch 495: loss=0.05270
Epoch 496: loss=0.05268
Epoch 497: loss=0.04981
Epoch 498: loss=0.05052
Epoch 499: loss=0.04977
Epoch 500: loss=0.04959
Training accuracy: 1.000
Test accuracy: 0.615

File list dumped

Saved in file
