slurmstepd: error: *** JOB 5145 ON gpunode2 CANCELLED AT 2021-10-26T08:50:22 ***
slurmstepd: error: *** STEP 5145.0 ON gpunode2 CANCELLED AT 2021-10-26T08:50:22 ***
original_recur.py:67: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  labels_ = np.array(y,dtype=np.int)
/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHD/dataset/shddataset/
init done
Epoch 1: loss=3.42377
Epoch 2: loss=2.92177
Epoch 3: loss=2.85360
Epoch 4: loss=2.78631
Epoch 5: loss=2.72090
Epoch 6: loss=2.63933
Epoch 7: loss=2.55380
Epoch 8: loss=2.47591
Epoch 9: loss=2.40074
Epoch 10: loss=2.32503
Epoch 11: loss=2.24703
Epoch 12: loss=2.17574
Epoch 13: loss=2.10538
Epoch 14: loss=2.04223
Epoch 15: loss=1.98681
Epoch 16: loss=1.92774
Epoch 17: loss=1.87212
Epoch 18: loss=1.81512
Epoch 19: loss=1.77010
Epoch 20: loss=1.71912
Epoch 21: loss=1.68372
Epoch 22: loss=1.63791
Epoch 23: loss=1.60326
Epoch 24: loss=1.56103
Epoch 25: loss=1.52316
Epoch 26: loss=1.49214
Epoch 27: loss=1.46704
Epoch 28: loss=1.42725
Epoch 29: loss=1.39225
Epoch 30: loss=1.36524
Epoch 31: loss=1.33612
Epoch 32: loss=1.31107
Epoch 33: loss=1.27762
Epoch 34: loss=1.25476
Epoch 35: loss=1.23813
Epoch 36: loss=1.20615
Epoch 37: loss=1.18069
Epoch 38: loss=1.16208
Epoch 39: loss=1.13753
Epoch 40: loss=1.11583
Epoch 41: loss=1.10258
Epoch 42: loss=1.08324
Epoch 43: loss=1.05618
Epoch 44: loss=1.05341
Epoch 45: loss=1.02763
Epoch 46: loss=1.00793
Epoch 47: loss=0.99947
Epoch 48: loss=0.97821
Epoch 49: loss=0.96975
Epoch 50: loss=0.95143
Epoch 51: loss=0.94075
Epoch 52: loss=0.91348
Epoch 53: loss=0.90822
Epoch 54: loss=0.89750
Epoch 55: loss=0.87650
Epoch 56: loss=0.86054
Epoch 57: loss=0.84714
Epoch 58: loss=0.83478
Epoch 59: loss=0.83252
Epoch 60: loss=0.81745
Epoch 61: loss=0.80698
Epoch 62: loss=0.79222
Epoch 63: loss=0.77637
Epoch 64: loss=0.77313
Epoch 65: loss=0.76182
Epoch 66: loss=0.75029
Epoch 67: loss=0.74157
Epoch 68: loss=0.72921
Epoch 69: loss=0.71925
Epoch 70: loss=0.71029
Epoch 71: loss=0.70470
Epoch 72: loss=0.69391
Epoch 73: loss=0.69357
Epoch 74: loss=0.67504
Epoch 75: loss=0.67198
Epoch 76: loss=0.66362
Epoch 77: loss=0.65797
Epoch 78: loss=0.64395
Epoch 79: loss=0.63357
Epoch 80: loss=0.62785
Epoch 81: loss=0.61973
Epoch 82: loss=0.61531
Epoch 83: loss=0.60834
Epoch 84: loss=0.61006
Epoch 85: loss=0.59500
Epoch 86: loss=0.59090
Epoch 87: loss=0.58162
Epoch 88: loss=0.58584
Epoch 89: loss=0.57314
Epoch 90: loss=0.56354
Epoch 91: loss=0.55546
Epoch 92: loss=0.55458
Epoch 93: loss=0.54409
Epoch 94: loss=0.54288
Epoch 95: loss=0.53908
Epoch 96: loss=0.52627
Epoch 97: loss=0.52260
Epoch 98: loss=0.51688
Epoch 99: loss=0.51305
Epoch 100: loss=0.49989
Epoch 101: loss=0.50000
Epoch 102: loss=0.49680
Epoch 103: loss=0.49197
Epoch 104: loss=0.48943
Epoch 105: loss=0.48172
Epoch 106: loss=0.47707
Epoch 107: loss=0.47142
Epoch 108: loss=0.46730
Epoch 109: loss=0.46429
Epoch 110: loss=0.45720
Epoch 111: loss=0.45132
Epoch 112: loss=0.44709
Epoch 113: loss=0.44203
Epoch 114: loss=0.43644
Epoch 115: loss=0.43845
Epoch 116: loss=0.43817
Epoch 117: loss=0.42579
Epoch 118: loss=0.42840
Epoch 119: loss=0.42435
Epoch 120: loss=0.42066
Epoch 121: loss=0.41462
Epoch 122: loss=0.40859
Epoch 123: loss=0.40299
Epoch 124: loss=0.40006
Epoch 125: loss=0.40486
Epoch 126: loss=0.39579
Epoch 127: loss=0.39020
Epoch 128: loss=0.38550
Epoch 129: loss=0.37702
Epoch 130: loss=0.38565
Epoch 131: loss=0.37899
Epoch 132: loss=0.37229
Epoch 133: loss=0.37124
Epoch 134: loss=0.36718
Epoch 135: loss=0.36688
Epoch 136: loss=0.36224
Epoch 137: loss=0.35561
Epoch 138: loss=0.35011
Epoch 139: loss=0.35122
Epoch 140: loss=0.35460
Epoch 141: loss=0.34010
Epoch 142: loss=0.34456
Epoch 143: loss=0.33943
Epoch 144: loss=0.33162
Epoch 145: loss=0.33465
Epoch 146: loss=0.33116
Epoch 147: loss=0.32217
Epoch 148: loss=0.32386
Epoch 149: loss=0.32437
Epoch 150: loss=0.32095
Epoch 151: loss=0.32143
Epoch 152: loss=0.32536
Epoch 153: loss=0.31764
Epoch 154: loss=0.31123
Epoch 155: loss=0.30275
Epoch 156: loss=0.30527
Epoch 157: loss=0.30187
Epoch 158: loss=0.30281
Epoch 159: loss=0.29602
Epoch 160: loss=0.29292
Epoch 161: loss=0.29141
Epoch 162: loss=0.30021
Epoch 163: loss=0.29001
Epoch 164: loss=0.28521
Epoch 165: loss=0.28340
Epoch 166: loss=0.28463
Epoch 167: loss=0.27480
Epoch 168: loss=0.27062
Epoch 169: loss=0.27787
Epoch 170: loss=0.26958
Epoch 171: loss=0.27042
Epoch 172: loss=0.26889
Epoch 173: loss=0.26946
Epoch 174: loss=0.26888
Epoch 175: loss=0.26370
Epoch 176: loss=0.26295
Epoch 177: loss=0.25761
Epoch 178: loss=0.25182
Epoch 179: loss=0.25445
Epoch 180: loss=0.25774
Epoch 181: loss=0.25016
Epoch 182: loss=0.25021
Epoch 183: loss=0.24391
Epoch 184: loss=0.24099
Epoch 185: loss=0.23784
Epoch 186: loss=0.24246
Epoch 187: loss=0.24039
Epoch 188: loss=0.23713
Epoch 189: loss=0.23279
Epoch 190: loss=0.23021
Epoch 191: loss=0.22608
Epoch 192: loss=0.22840
Epoch 193: loss=0.22442
Epoch 194: loss=0.22806
Epoch 195: loss=0.22731
Epoch 196: loss=0.22434
Epoch 197: loss=0.22028
Epoch 198: loss=0.21962
Epoch 199: loss=0.22168
Epoch 200: loss=0.22221
Training accuracy: 0.978
Test accuracy: 0.666
Traceback (most recent call last):
  File "original_recur.py", line 253, in <module>
    pickle.dump(loss_list,open_file)
NameError: name 'pickle' is not defined
srun: error: gpunode2: task 0: Exited with exit code 1
