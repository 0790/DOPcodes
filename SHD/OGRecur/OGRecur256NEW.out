/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHD/dataset/shddataset/
init done
Epoch 1: loss=3.31300
Epoch 2: loss=2.89233
Epoch 3: loss=2.79912
Epoch 4: loss=2.69586
Epoch 5: loss=2.58884
Epoch 6: loss=2.48191
Epoch 7: loss=2.38361
Epoch 8: loss=2.27695
Epoch 9: loss=2.18096
Epoch 10: loss=2.09206
Epoch 11: loss=2.00791
Epoch 12: loss=1.94289
Epoch 13: loss=1.87728
Epoch 14: loss=1.81738
Epoch 15: loss=1.76667
Epoch 16: loss=1.71020
Epoch 17: loss=1.66435
Epoch 18: loss=1.61793
Epoch 19: loss=1.57743
Epoch 20: loss=1.54074
Epoch 21: loss=1.50111
Epoch 22: loss=1.46857
Epoch 23: loss=1.42362
Epoch 24: loss=1.39277
Epoch 25: loss=1.35675
Epoch 26: loss=1.33306
Epoch 27: loss=1.30140
Epoch 28: loss=1.27853
Epoch 29: loss=1.24778
Epoch 30: loss=1.22531
Epoch 31: loss=1.19644
Epoch 32: loss=1.16728
Epoch 33: loss=1.14758
Epoch 34: loss=1.12212
Epoch 35: loss=1.09834
Epoch 36: loss=1.08046
Epoch 37: loss=1.06144
Epoch 38: loss=1.04416
Epoch 39: loss=1.02320
Epoch 40: loss=1.00128
Epoch 41: loss=0.98748
Epoch 42: loss=0.97218
Epoch 43: loss=0.95551
Epoch 44: loss=0.94606
Epoch 45: loss=0.92111
Epoch 46: loss=0.90722
Epoch 47: loss=0.89317
Epoch 48: loss=0.87627
Epoch 49: loss=0.86100
Epoch 50: loss=0.85518
Epoch 51: loss=0.83979
Epoch 52: loss=0.82799
Epoch 53: loss=0.81255
Epoch 54: loss=0.79728
Epoch 55: loss=0.78939
Epoch 56: loss=0.77853
Epoch 57: loss=0.76717
Epoch 58: loss=0.75457
Epoch 59: loss=0.74709
Epoch 60: loss=0.73915
Epoch 61: loss=0.72685
Epoch 62: loss=0.71769
Epoch 63: loss=0.71258
Epoch 64: loss=0.70122
Epoch 65: loss=0.69605
Epoch 66: loss=0.67777
Epoch 67: loss=0.66778
Epoch 68: loss=0.66465
Epoch 69: loss=0.65218
Epoch 70: loss=0.64089
Epoch 71: loss=0.63483
Epoch 72: loss=0.62743
Epoch 73: loss=0.61765
Epoch 74: loss=0.61640
Epoch 75: loss=0.60779
Epoch 76: loss=0.59810
Epoch 77: loss=0.59176
Epoch 78: loss=0.57732
Epoch 79: loss=0.57842
Epoch 80: loss=0.57629
Epoch 81: loss=0.56322
Epoch 82: loss=0.55699
Epoch 83: loss=0.54739
Epoch 84: loss=0.54206
Epoch 85: loss=0.53727
Epoch 86: loss=0.52821
Epoch 87: loss=0.52060
Epoch 88: loss=0.52603
Epoch 89: loss=0.51508
Epoch 90: loss=0.50675
Epoch 91: loss=0.49854
Epoch 92: loss=0.50173
Epoch 93: loss=0.49668
Epoch 94: loss=0.49462
Epoch 95: loss=0.48414
Epoch 96: loss=0.47811
Epoch 97: loss=0.47607
Epoch 98: loss=0.47439
Epoch 99: loss=0.45953
Epoch 100: loss=0.46669
Epoch 101: loss=0.45245
Epoch 102: loss=0.44568
Epoch 103: loss=0.44236
Epoch 104: loss=0.43305
Epoch 105: loss=0.42922
Epoch 106: loss=0.43003
Epoch 107: loss=0.42839
Epoch 108: loss=0.42315
Epoch 109: loss=0.41892
Epoch 110: loss=0.41221
Epoch 111: loss=0.41004
Epoch 112: loss=0.39982
Epoch 113: loss=0.39647
Epoch 114: loss=0.39614
Epoch 115: loss=0.39343
Epoch 116: loss=0.38647
Epoch 117: loss=0.38372
Epoch 118: loss=0.38168
Epoch 119: loss=0.37708
Epoch 120: loss=0.37241
Epoch 121: loss=0.36918
Epoch 122: loss=0.36171
Epoch 123: loss=0.35770
Epoch 124: loss=0.35475
Epoch 125: loss=0.35271
Epoch 126: loss=0.34704
Epoch 127: loss=0.35125
Epoch 128: loss=0.34823
Epoch 129: loss=0.34900
Epoch 130: loss=0.34299
Epoch 131: loss=0.33129
Epoch 132: loss=0.33828
Epoch 133: loss=0.33375
Epoch 134: loss=0.33670
Epoch 135: loss=0.32541
Epoch 136: loss=0.31886
Epoch 137: loss=0.31366
Epoch 138: loss=0.31671
Epoch 139: loss=0.31409
Epoch 140: loss=0.30808
Epoch 141: loss=0.31296
Epoch 142: loss=0.30958
Epoch 143: loss=0.30051
Epoch 144: loss=0.29747
Epoch 145: loss=0.29756
Epoch 146: loss=0.29022
Epoch 147: loss=0.29359
Epoch 148: loss=0.29063
Epoch 149: loss=0.28514
Epoch 150: loss=0.28277
Epoch 151: loss=0.27848
Epoch 152: loss=0.27649
Epoch 153: loss=0.27530
Epoch 154: loss=0.27254
Epoch 155: loss=0.27299
Epoch 156: loss=0.27482
Epoch 157: loss=0.26712
Epoch 158: loss=0.26267
Epoch 159: loss=0.26321
Epoch 160: loss=0.26075
Epoch 161: loss=0.25574
Epoch 162: loss=0.25902
Epoch 163: loss=0.25546
Epoch 164: loss=0.25121
Epoch 165: loss=0.25575
Epoch 166: loss=0.24784
Epoch 167: loss=0.24651
Epoch 168: loss=0.24134
Epoch 169: loss=0.23584
Epoch 170: loss=0.24261
Epoch 171: loss=0.23935
Epoch 172: loss=0.23796
Epoch 173: loss=0.23055
Epoch 174: loss=0.23169
Epoch 175: loss=0.22798
Epoch 176: loss=0.23739
Epoch 177: loss=0.22462
Epoch 178: loss=0.22291
Epoch 179: loss=0.22152
Epoch 180: loss=0.22504
Epoch 181: loss=0.22260
Epoch 182: loss=0.21705
Epoch 183: loss=0.21827
Epoch 184: loss=0.21236
Epoch 185: loss=0.21474
Epoch 186: loss=0.21134
Epoch 187: loss=0.20655
Epoch 188: loss=0.20396
Epoch 189: loss=0.20276
Epoch 190: loss=0.20057
Epoch 191: loss=0.20298
Epoch 192: loss=0.20265
Epoch 193: loss=0.19767
Epoch 194: loss=0.20366
Epoch 195: loss=0.19526
Epoch 196: loss=0.19666
Epoch 197: loss=0.20002
Epoch 198: loss=0.19313
Epoch 199: loss=0.19537
Epoch 200: loss=0.19829
Epoch 201: loss=0.18708
Epoch 202: loss=0.18459
Epoch 203: loss=0.19097
Epoch 204: loss=0.18487
Epoch 205: loss=0.18456
Epoch 206: loss=0.18057
Epoch 207: loss=0.17972
Epoch 208: loss=0.18194
Epoch 209: loss=0.18071
Epoch 210: loss=0.17973
Epoch 211: loss=0.17697
Epoch 212: loss=0.17321
Epoch 213: loss=0.17411
Epoch 214: loss=0.17158
Epoch 215: loss=0.17062
Epoch 216: loss=0.17054
Epoch 217: loss=0.16791
Epoch 218: loss=0.17048
Epoch 219: loss=0.17096
Epoch 220: loss=0.16621
Epoch 221: loss=0.16545
Epoch 222: loss=0.16353
Epoch 223: loss=0.16146
Epoch 224: loss=0.16163
Epoch 225: loss=0.15908
Epoch 226: loss=0.15978
Epoch 227: loss=0.15820
Epoch 228: loss=0.16474
Epoch 229: loss=0.16246
Epoch 230: loss=0.15876
Epoch 231: loss=0.15140
Epoch 232: loss=0.15385
Epoch 233: loss=0.15340
Epoch 234: loss=0.15280
Epoch 235: loss=0.15269
Epoch 236: loss=0.14855
Epoch 237: loss=0.14542
Epoch 238: loss=0.14465
Epoch 239: loss=0.14221
Epoch 240: loss=0.14170
Epoch 241: loss=0.14403
Epoch 242: loss=0.14439
Epoch 243: loss=0.14385
Epoch 244: loss=0.14173
Epoch 245: loss=0.14311
Epoch 246: loss=0.13688
Epoch 247: loss=0.13784
Epoch 248: loss=0.13603
Epoch 249: loss=0.13629
Epoch 250: loss=0.13611
Epoch 251: loss=0.14410
Epoch 252: loss=0.13869
Epoch 253: loss=0.13554
Epoch 254: loss=0.13431
Epoch 255: loss=0.12872
Epoch 256: loss=0.13394
Epoch 257: loss=0.13376
Epoch 258: loss=0.12937
Epoch 259: loss=0.12962
Epoch 260: loss=0.12811
Epoch 261: loss=0.13366
Epoch 262: loss=0.13467
Epoch 263: loss=0.12755
Epoch 264: loss=0.12291
Epoch 265: loss=0.12667
Epoch 266: loss=0.12529
Epoch 267: loss=0.12252
Epoch 268: loss=0.12249
Epoch 269: loss=0.12415
Epoch 270: loss=0.12014
Epoch 271: loss=0.11877
Epoch 272: loss=0.11893
Epoch 273: loss=0.11721
Epoch 274: loss=0.11971
Epoch 275: loss=0.11985
Epoch 276: loss=0.12401
Epoch 277: loss=0.11617
Epoch 278: loss=0.11766
Epoch 279: loss=0.11711
Epoch 280: loss=0.11273
Epoch 281: loss=0.11182
Epoch 282: loss=0.11026
Epoch 283: loss=0.11077
Epoch 284: loss=0.10962
Epoch 285: loss=0.10768
Epoch 286: loss=0.10781
Epoch 287: loss=0.10840
Epoch 288: loss=0.10819
Epoch 289: loss=0.11192
Epoch 290: loss=0.10859
Epoch 291: loss=0.10623
Epoch 292: loss=0.10670
Epoch 293: loss=0.10421
Epoch 294: loss=0.10634
Epoch 295: loss=0.10667
Epoch 296: loss=0.10518
Epoch 297: loss=0.10287
Epoch 298: loss=0.10262
Epoch 299: loss=0.10371
Epoch 300: loss=0.10273
Epoch 301: loss=0.11026
Epoch 302: loss=0.10382
Epoch 303: loss=0.10094
Epoch 304: loss=0.10073
Epoch 305: loss=0.09990
Epoch 306: loss=0.10013
Epoch 307: loss=0.09898
Epoch 308: loss=0.09657
Epoch 309: loss=0.09436
Epoch 310: loss=0.09922
Epoch 311: loss=0.09996
Epoch 312: loss=0.10568
Epoch 313: loss=0.09659
Epoch 314: loss=0.09419
Epoch 315: loss=0.09187
Epoch 316: loss=0.09373
Epoch 317: loss=0.09612
Epoch 318: loss=0.09439
Epoch 319: loss=0.09336
Epoch 320: loss=0.09168
Epoch 321: loss=0.09080
Epoch 322: loss=0.09380
Epoch 323: loss=0.09612
Epoch 324: loss=0.09039
Epoch 325: loss=0.08874
Epoch 326: loss=0.08885
Epoch 327: loss=0.08737
Epoch 328: loss=0.08720
Epoch 329: loss=0.08866
Epoch 330: loss=0.08864
Epoch 331: loss=0.08717
Epoch 332: loss=0.08578
Epoch 333: loss=0.08386
Epoch 334: loss=0.08701
Epoch 335: loss=0.08664
Epoch 336: loss=0.08836
Epoch 337: loss=0.09343
Epoch 338: loss=0.08921
Epoch 339: loss=0.08516
Epoch 340: loss=0.08510
Epoch 341: loss=0.08694
original_recur.py:67: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  labels_ = np.array(y,dtype=np.int)
Epoch 342: loss=0.08535
Epoch 343: loss=0.08337
Epoch 344: loss=0.08795
Epoch 345: loss=0.09245
Epoch 346: loss=0.09061
Epoch 347: loss=0.08959
Epoch 348: loss=0.08338
Epoch 349: loss=0.08152
Epoch 350: loss=0.07977
Epoch 351: loss=0.07980
Epoch 352: loss=0.08176
Epoch 353: loss=0.07909
Epoch 354: loss=0.07843
Epoch 355: loss=0.08149
Epoch 356: loss=0.08034
Epoch 357: loss=0.08095
Epoch 358: loss=0.07980
Epoch 359: loss=0.07909
Epoch 360: loss=0.07857
Epoch 361: loss=0.07764
Epoch 362: loss=0.07792
Epoch 363: loss=0.07754
Epoch 364: loss=0.07991
Epoch 365: loss=0.07733
Epoch 366: loss=0.07730
Epoch 367: loss=0.07464
Epoch 368: loss=0.07459
Epoch 369: loss=0.07537
Epoch 370: loss=0.07592
Epoch 371: loss=0.07832
Epoch 372: loss=0.08077
Epoch 373: loss=0.07416
Epoch 374: loss=0.07053
Epoch 375: loss=0.07139
Epoch 376: loss=0.07131
Epoch 377: loss=0.07280
Epoch 378: loss=0.07190
Epoch 379: loss=0.07419
Epoch 380: loss=0.07318
Epoch 381: loss=0.07290
Epoch 382: loss=0.07156
Epoch 383: loss=0.06982
Epoch 384: loss=0.07311
Epoch 385: loss=0.07092
Epoch 386: loss=0.07100
Epoch 387: loss=0.07039
Epoch 388: loss=0.06994
Epoch 389: loss=0.06837
Epoch 390: loss=0.06866
Epoch 391: loss=0.06981
Epoch 392: loss=0.06939
Epoch 393: loss=0.06822
Epoch 394: loss=0.06942
Epoch 395: loss=0.06897
Epoch 396: loss=0.06944
Epoch 397: loss=0.06966
Epoch 398: loss=0.06898
Epoch 399: loss=0.07094
Epoch 400: loss=0.06991
Epoch 401: loss=0.06692
Epoch 402: loss=0.06668
Epoch 403: loss=0.06759
Epoch 404: loss=0.06545
Epoch 405: loss=0.06388
Epoch 406: loss=0.06359
Epoch 407: loss=0.06465
Epoch 408: loss=0.06603
Epoch 409: loss=0.06658
Epoch 410: loss=0.06778
Epoch 411: loss=0.06521
Epoch 412: loss=0.06241
Epoch 413: loss=0.06253
Epoch 414: loss=0.06214
Epoch 415: loss=0.06114
Epoch 416: loss=0.06293
Epoch 417: loss=0.06240
Epoch 418: loss=0.06381
Epoch 419: loss=0.06469
Epoch 420: loss=0.06253
Epoch 421: loss=0.06160
Epoch 422: loss=0.06046
Epoch 423: loss=0.06420
Epoch 424: loss=0.06456
Epoch 425: loss=0.06325
Epoch 426: loss=0.06698
Epoch 427: loss=0.06388
Epoch 428: loss=0.06013
Epoch 429: loss=0.06201
Epoch 430: loss=0.06031
Epoch 431: loss=0.05912
Epoch 432: loss=0.05956
Epoch 433: loss=0.05942
Epoch 434: loss=0.06047
Epoch 435: loss=0.06003
Epoch 436: loss=0.05991
Epoch 437: loss=0.05920
Epoch 438: loss=0.05935
Epoch 439: loss=0.05790
Epoch 440: loss=0.05646
Epoch 441: loss=0.05685
Epoch 442: loss=0.05766
Epoch 443: loss=0.05768
Epoch 444: loss=0.05714
Epoch 445: loss=0.05772
Epoch 446: loss=0.05930
Epoch 447: loss=0.05735
Epoch 448: loss=0.05775
Epoch 449: loss=0.05867
Epoch 450: loss=0.06268
Epoch 451: loss=0.05961
Epoch 452: loss=0.05773
Epoch 453: loss=0.05542
Epoch 454: loss=0.05654
Epoch 455: loss=0.05500
Epoch 456: loss=0.05454
Epoch 457: loss=0.05500
Epoch 458: loss=0.05746
Epoch 459: loss=0.05692
Epoch 460: loss=0.05473
Epoch 461: loss=0.05338
Epoch 462: loss=0.05553
Epoch 463: loss=0.05494
Epoch 464: loss=0.05448
Epoch 465: loss=0.05485
Epoch 466: loss=0.05399
Epoch 467: loss=0.05334
Epoch 468: loss=0.05393
Epoch 469: loss=0.05437
Epoch 470: loss=0.05468
Epoch 471: loss=0.05773
Epoch 472: loss=0.05607
Epoch 473: loss=0.05482
Epoch 474: loss=0.05569
Epoch 475: loss=0.05497
Epoch 476: loss=0.05403
Epoch 477: loss=0.05228
Epoch 478: loss=0.05097
Epoch 479: loss=0.05152
Epoch 480: loss=0.05060
Epoch 481: loss=0.05062
Epoch 482: loss=0.05259
Epoch 483: loss=0.05300
Epoch 484: loss=0.05206
Epoch 485: loss=0.05087
Epoch 486: loss=0.04972
Epoch 487: loss=0.05201
Epoch 488: loss=0.05152
Epoch 489: loss=0.05371
Epoch 490: loss=0.05602
Epoch 491: loss=0.05224
Epoch 492: loss=0.05038
Epoch 493: loss=0.04973
Epoch 494: loss=0.04942
Epoch 495: loss=0.04863
Epoch 496: loss=0.04823
Epoch 497: loss=0.04935
Epoch 498: loss=0.05154
Epoch 499: loss=0.05129
Epoch 500: loss=0.05263
Training accuracy: 1.000
Test accuracy: 0.627

File list dumped

Saved in file
