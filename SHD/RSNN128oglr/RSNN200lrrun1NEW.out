Lmod has detected the following error: The following module(s) are unknown:
"cuda-11.0.2-gcc-10.2.0-3wlbq6u"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda-11.0.2-gcc-10.2.0-3wlbq6u"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/home/venkat/Unreliable_Synaptic_Transmission/Deepti/DOPcodes/SHD/dataset/shddataset/
File not present for network with uniform weight initialisation
Initialised with numbers from uniform distribution
Epoch 1: loss=21.58963
Epoch 2: loss=3.83197
Epoch 3: loss=3.16557
Epoch 4: loss=2.95041
Epoch 5: loss=2.84685
Epoch 6: loss=2.67012
Epoch 7: loss=2.54389
Epoch 8: loss=2.49161
Epoch 9: loss=2.47640
Epoch 10: loss=2.31597
Trained for 10 epochs
Training accuracy: 0.387
Epoch 1: loss=2.24155
Epoch 2: loss=2.16825
Epoch 3: loss=2.08151
Epoch 4: loss=2.04565
Epoch 5: loss=1.95711
Epoch 6: loss=1.89164
Epoch 7: loss=1.81922
Epoch 8: loss=1.80607
Epoch 9: loss=1.75913
Epoch 10: loss=1.70992
Epoch 11: loss=1.65474
Epoch 12: loss=1.57934
Epoch 13: loss=1.51133
Epoch 14: loss=1.47790
Epoch 15: loss=1.49194
Epoch 16: loss=1.45703
Epoch 17: loss=1.38356
Epoch 18: loss=1.38642
Epoch 19: loss=1.33664
Epoch 20: loss=1.31790
Epoch 21: loss=1.26558
Epoch 22: loss=1.27509
Epoch 23: loss=1.24902
Epoch 24: loss=1.21610
Epoch 25: loss=1.18118
Epoch 26: loss=1.17764
Epoch 27: loss=1.17031
Epoch 28: loss=1.13400
Epoch 29: loss=1.08879
Epoch 30: loss=1.08128
Epoch 31: loss=1.04648
Epoch 32: loss=1.01858
Epoch 33: loss=1.02741
Epoch 34: loss=1.02940
Epoch 35: loss=0.99378
Epoch 36: loss=0.98856
Epoch 37: loss=0.98571
Epoch 38: loss=0.96518
Epoch 39: loss=0.95479
Epoch 40: loss=0.92704
Epoch 41: loss=0.93290
Epoch 42: loss=0.89817
Epoch 43: loss=0.90249
Epoch 44: loss=0.92627
Epoch 45: loss=0.87863
Epoch 46: loss=0.86317
Epoch 47: loss=0.84639
Epoch 48: loss=0.87870
Epoch 49: loss=0.85638
Epoch 50: loss=0.83611
Epoch 51: loss=0.82955
Epoch 52: loss=0.79604
Epoch 53: loss=0.79426
Epoch 54: loss=0.82824
Epoch 55: loss=0.84081
Epoch 56: loss=0.80939
Epoch 57: loss=0.76374
Epoch 58: loss=0.75280
Epoch 59: loss=0.75144
Epoch 60: loss=0.75094
Epoch 61: loss=0.74348
Epoch 62: loss=0.76595
Epoch 63: loss=0.72380
Epoch 64: loss=0.73987
Epoch 65: loss=0.69057
Epoch 66: loss=0.68794
Epoch 67: loss=0.72030
Epoch 68: loss=0.73174
Epoch 69: loss=0.70448
Epoch 70: loss=0.71079
Epoch 71: loss=0.68658
Epoch 72: loss=0.69708
Epoch 73: loss=0.69448
Epoch 74: loss=0.66437
Epoch 75: loss=0.63567
Epoch 76: loss=0.70785
Epoch 77: loss=0.67073
Epoch 78: loss=0.64544
Epoch 79: loss=0.62989
Epoch 80: loss=0.64684
Epoch 81: loss=0.66819
Epoch 82: loss=0.61413
Epoch 83: loss=0.63956
Epoch 84: loss=0.61027
Epoch 85: loss=0.61421
Epoch 86: loss=0.61987
Epoch 87: loss=0.60226
Epoch 88: loss=0.57785
Epoch 89: loss=0.61177
Epoch 90: loss=0.59024
Epoch 91: loss=0.61106
Epoch 92: loss=0.58129
Epoch 93: loss=0.58071
Epoch 94: loss=0.56005
Epoch 95: loss=0.56148
Epoch 96: loss=0.55008
Epoch 97: loss=0.55288
Epoch 98: loss=0.55573
Epoch 99: loss=0.56521
Epoch 100: loss=0.55609
Epoch 101: loss=0.54415
Epoch 102: loss=0.50321
Epoch 103: loss=0.52123
Epoch 104: loss=0.55117
Epoch 105: loss=0.53509
Epoch 106: loss=0.50324
Epoch 107: loss=0.51723
Epoch 108: loss=0.50053
Epoch 109: loss=0.49889
Epoch 110: loss=0.46930
Epoch 111: loss=0.46744
Epoch 112: loss=0.46931
Epoch 113: loss=0.46412
Epoch 114: loss=0.49379
Epoch 115: loss=0.48577
Epoch 116: loss=0.46589
Epoch 117: loss=0.47176
Epoch 118: loss=0.46820
Epoch 119: loss=0.45343
Epoch 120: loss=0.46901
Epoch 121: loss=0.46208
Epoch 122: loss=0.45965
Epoch 123: loss=0.47636
Epoch 124: loss=0.45176
Epoch 125: loss=0.44441
Epoch 126: loss=0.44792
Epoch 127: loss=0.44576
Epoch 128: loss=0.43804
Epoch 129: loss=0.44609
Epoch 130: loss=0.43125
Epoch 131: loss=0.43160
Epoch 132: loss=0.42483
Epoch 133: loss=0.40711
Epoch 134: loss=0.42421
Epoch 135: loss=0.41015
Epoch 136: loss=0.44373
Epoch 137: loss=0.42840
Epoch 138: loss=0.43104
Epoch 139: loss=0.42148
Epoch 140: loss=0.40768
Epoch 141: loss=0.40583
Epoch 142: loss=0.43583
Epoch 143: loss=0.38947
Epoch 144: loss=0.37942
Epoch 145: loss=0.39038
Epoch 146: loss=0.40465
Epoch 147: loss=0.39756
Epoch 148: loss=0.38682
Epoch 149: loss=0.37398
Epoch 150: loss=0.39892
Epoch 151: loss=0.39020
Epoch 152: loss=0.40058
Epoch 153: loss=0.39365
Epoch 154: loss=0.39804
Epoch 155: loss=0.37902
Epoch 156: loss=0.35870
Epoch 157: loss=0.36349
Epoch 158: loss=0.37195
Epoch 159: loss=0.37837
Epoch 160: loss=0.36484
Epoch 161: loss=0.34520
Epoch 162: loss=0.35675
Epoch 163: loss=0.35180
Epoch 164: loss=0.36267
Epoch 165: loss=0.34662
Epoch 166: loss=0.35683
Epoch 167: loss=0.33901
Epoch 168: loss=0.35495
Epoch 169: loss=0.35020
Epoch 170: loss=0.34080
Epoch 171: loss=0.34971
Epoch 172: loss=0.33710
Epoch 173: loss=0.33762
Epoch 174: loss=0.33582
Epoch 175: loss=0.34797
Epoch 176: loss=0.34731
Epoch 177: loss=0.33690
Epoch 178: loss=0.35278
Epoch 179: loss=0.32990
Epoch 180: loss=0.32259
Epoch 181: loss=0.31968
Epoch 182: loss=0.32442
Epoch 183: loss=0.31868
Epoch 184: loss=0.32698
Epoch 185: loss=0.32238
Epoch 186: loss=0.32713
Epoch 187: loss=0.33299
Epoch 188: loss=0.31762
Epoch 189: loss=0.31624
Epoch 190: loss=0.30776
Epoch 191: loss=0.32075
Epoch 192: loss=0.32244
Epoch 193: loss=0.31180
Epoch 194: loss=0.30880
Epoch 195: loss=0.30188
Epoch 196: loss=0.29556
Epoch 197: loss=0.29913
Epoch 198: loss=0.31335
Epoch 199: loss=0.33466
Epoch 200: loss=0.30953
Epoch 201: loss=0.29859
Epoch 202: loss=0.31148
Epoch 203: loss=0.29399
Epoch 204: loss=0.29850
Epoch 205: loss=0.28836
Epoch 206: loss=0.29814
Epoch 207: loss=0.29935
Epoch 208: loss=0.29593
Epoch 209: loss=0.31089
Epoch 210: loss=0.29729
Epoch 211: loss=0.28721
Epoch 212: loss=0.27883
Epoch 213: loss=0.30272
Epoch 214: loss=0.29840
Epoch 215: loss=0.30025
Epoch 216: loss=0.28827
Epoch 217: loss=0.29181
Epoch 218: loss=0.28719
Epoch 219: loss=0.27587
Epoch 220: loss=0.29961
Epoch 221: loss=0.29587
Epoch 222: loss=0.29882
Epoch 223: loss=0.29368
Epoch 224: loss=0.28800
Epoch 225: loss=0.27083
Epoch 226: loss=0.27565
Epoch 227: loss=0.27633
Epoch 228: loss=0.28525
Epoch 229: loss=0.28466
Epoch 230: loss=0.26289
Epoch 231: loss=0.29304
Epoch 232: loss=0.27295
Epoch 233: loss=0.27912
Epoch 234: loss=0.28520
Epoch 235: loss=0.27570
Epoch 236: loss=0.27560
Epoch 237: loss=0.26640
Epoch 238: loss=0.26886
Epoch 239: loss=0.26030
Epoch 240: loss=0.25296
Epoch 241: loss=0.26283
Epoch 242: loss=0.25774
Epoch 243: loss=0.27039
Epoch 244: loss=0.26063
Epoch 245: loss=0.27402
Epoch 246: loss=0.26051
Epoch 247: loss=0.27060
Epoch 248: loss=0.27524
Epoch 249: loss=0.25587
Epoch 250: loss=0.27383
Epoch 251: loss=0.28271
Epoch 252: loss=0.28121
Epoch 253: loss=0.28498
Epoch 254: loss=0.26738
Epoch 255: loss=0.26885
Epoch 256: loss=0.28040
Epoch 257: loss=0.25224
Epoch 258: loss=0.25812
Epoch 259: loss=0.26229
Epoch 260: loss=0.25319
Epoch 261: loss=0.26891
Epoch 262: loss=0.26569
Epoch 263: loss=0.26234
Epoch 264: loss=0.25439
Epoch 265: loss=0.24925
Epoch 266: loss=0.25071
Epoch 267: loss=0.25955
Epoch 268: loss=0.26458
Epoch 269: loss=0.25018
Epoch 270: loss=0.25468
Epoch 271: loss=0.24065
Epoch 272: loss=0.25744
Epoch 273: loss=0.24204
Epoch 274: loss=0.24951
Epoch 275: loss=0.25793
Epoch 276: loss=0.24804
Epoch 277: loss=0.26223
Epoch 278: loss=0.25913
Epoch 279: loss=0.24124
Epoch 280: loss=0.23756
Epoch 281: loss=0.24773
Epoch 282: loss=0.24238
Epoch 283: loss=0.24586
Epoch 284: loss=0.25244
Epoch 285: loss=0.27386
Epoch 286: loss=0.25186
Epoch 287: loss=0.25443
Epoch 288: loss=0.24487
Epoch 289: loss=0.24909
Epoch 290: loss=0.24307
Epoch 291: loss=0.26850
Epoch 292: loss=0.25681
Epoch 293: loss=0.24240
Epoch 294: loss=0.24102
Epoch 295: loss=0.27793
Epoch 296: loss=0.26071
Epoch 297: loss=0.24425
Epoch 298: loss=0.23676
Epoch 299: loss=0.24288
Epoch 300: loss=0.23673
Epoch 301: loss=0.25068
Epoch 302: loss=0.24004
Epoch 303: loss=0.24325
Epoch 304: loss=0.24852
Epoch 305: loss=0.24509
Epoch 306: loss=0.23145
Epoch 307: loss=0.23688
Epoch 308: loss=0.22803
Epoch 309: loss=0.25067
Epoch 310: loss=0.26541
Epoch 311: loss=0.23763
Epoch 312: loss=0.23701
Epoch 313: loss=0.23591
Epoch 314: loss=0.23598
Epoch 315: loss=0.24137
Epoch 316: loss=0.24461
Epoch 317: loss=0.23088
Epoch 318: loss=0.23471
Epoch 319: loss=0.23698
Epoch 320: loss=0.23546
Epoch 321: loss=0.23545
Epoch 322: loss=0.24277
Epoch 323: loss=0.23942
Epoch 324: loss=0.22626
Epoch 325: loss=0.24334
Epoch 326: loss=0.23524
Epoch 327: loss=0.23600
Epoch 328: loss=0.22230
Epoch 329: loss=0.21827
Epoch 330: loss=0.22054
Epoch 331: loss=0.22732
Epoch 332: loss=0.22556
Epoch 333: loss=0.21757
Epoch 334: loss=0.23171
Epoch 335: loss=0.21578
Epoch 336: loss=0.21944
Epoch 337: loss=0.23358
Epoch 338: loss=0.22864
Epoch 339: loss=0.22294
Epoch 340: loss=0.23142
Epoch 341: loss=0.24287
Epoch 342: loss=0.23334
Epoch 343: loss=0.23087
Epoch 344: loss=0.22079
Epoch 345: loss=0.25050
Epoch 346: loss=0.25568
Epoch 347: loss=0.21591
Epoch 348: loss=0.22009
Epoch 349: loss=0.23686
Epoch 350: loss=0.24248
Epoch 351: loss=0.22499
Epoch 352: loss=0.21331
Epoch 353: loss=0.23097
Epoch 354: loss=0.24138
Epoch 355: loss=0.22065
Epoch 356: loss=0.22183
Epoch 357: loss=0.22180
Epoch 358: loss=0.22468
Epoch 359: loss=0.21967
Epoch 360: loss=0.22316
Epoch 361: loss=0.22017
Epoch 362: loss=0.22010
Epoch 363: loss=0.22316
Epoch 364: loss=0.21096
Epoch 365: loss=0.22155
Epoch 366: loss=0.23022
Epoch 367: loss=0.23271
Epoch 368: loss=0.22418
Epoch 369: loss=0.22329
Epoch 370: loss=0.21704
Epoch 371: loss=0.21836
Epoch 372: loss=0.21655
Epoch 373: loss=0.21848
Epoch 374: loss=0.22724
Epoch 375: loss=0.22361
Epoch 376: loss=0.22775
Epoch 377: loss=0.20744
Epoch 378: loss=0.22241
Epoch 379: loss=0.21845
Epoch 380: loss=0.21801
Epoch 381: loss=0.22753
Epoch 382: loss=0.22044
Epoch 383: loss=0.21841
Epoch 384: loss=0.23433
Epoch 385: loss=0.21448
Epoch 386: loss=0.22296
Epoch 387: loss=0.21653
Epoch 388: loss=0.22586
Epoch 389: loss=0.22943
Epoch 390: loss=0.21165
Epoch 391: loss=0.22152
Epoch 392: loss=0.21513
Epoch 393: loss=0.21690
Epoch 394: loss=0.21709
Epoch 395: loss=0.22347
Epoch 396: loss=0.23728
Epoch 397: loss=0.20773
Epoch 398: loss=0.22239
Epoch 399: loss=0.21950
Epoch 400: loss=0.22123
Training accuracy: 0.962
Test accuracy: 0.594

File list dumped

Saved in file
500 epochs recur round 2
are new values in file?
